# AgentlyFormat æœ€ä½³å®è·µæŒ‡å—

## ğŸ“‹ ç›®å½•

1. [æ¦‚è¿°](#æ¦‚è¿°)
2. [æ™ºèƒ½JSONè¡¥å…¨æœ€ä½³å®è·µ](#æ™ºèƒ½jsonè¡¥å…¨æœ€ä½³å®è·µ)
3. [æµå¼JSONè§£ææœ€ä½³å®è·µ](#æµå¼jsonè§£ææœ€ä½³å®è·µ)
4. [æ•°æ®è·¯å¾„æ„å»ºæœ€ä½³å®è·µ](#æ•°æ®è·¯å¾„æ„å»ºæœ€ä½³å®è·µ)
5. [SchemaéªŒè¯æœ€ä½³å®è·µ](#schemaéªŒè¯æœ€ä½³å®è·µ)
6. [å·®åˆ†å¼•æ“æœ€ä½³å®è·µ](#å·®åˆ†å¼•æ“æœ€ä½³å®è·µ)
7. [å¤šæ¨¡å‹é€‚é…å™¨æœ€ä½³å®è·µ](#å¤šæ¨¡å‹é€‚é…å™¨æœ€ä½³å®è·µ)
8. [ç»¼åˆåº”ç”¨æ¡ˆä¾‹](#ç»¼åˆåº”ç”¨æ¡ˆä¾‹)
9. [å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ](#å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ)
10. [æ€§èƒ½ä¼˜åŒ–å»ºè®®](#æ€§èƒ½ä¼˜åŒ–å»ºè®®)

---

## ğŸ“– æ¦‚è¿°

æœ¬æŒ‡å—æä¾›AgentlyFormaté¡¹ç›®å„æ ¸å¿ƒåŠŸèƒ½çš„æœ€ä½³å®è·µæ¡ˆä¾‹ï¼Œé€šè¿‡çœŸå®åœºæ™¯å’Œå®Œæ•´ä»£ç ç¤ºä¾‹ï¼Œå¸®åŠ©å¼€å‘è€…å¿«é€ŸæŒæ¡é¡¹ç›®çš„ä½¿ç”¨æ–¹æ³•å’Œæ ¸å¿ƒèƒ½åŠ›ã€‚

### é€‚ç”¨äººç¾¤
- Pythonåˆå­¦è€…
- å¤§æ¨¡å‹åº”ç”¨å¼€å‘è€…
- JSONæ•°æ®å¤„ç†å·¥ç¨‹å¸ˆ
- APIæœåŠ¡å¼€å‘è€…

### å‰ç½®è¦æ±‚
```bash
# å®‰è£…AgentlyFormat
pip install AgentlyFormat

# æˆ–å¼€å‘ç¯å¢ƒå®‰è£…
pip install -e ".[dev]"
```

---

## ğŸ”§ æ™ºèƒ½JSONè¡¥å…¨æœ€ä½³å®è·µ

### åº”ç”¨åœºæ™¯1ï¼šå¤„ç†å¤§æ¨¡å‹ä¸å®Œæ•´è¾“å‡º

**åœºæ™¯æè¿°**ï¼šChatGPTç­‰å¤§æ¨¡å‹åœ¨ç”ŸæˆJSONæ—¶ç»å¸¸å› ä¸ºtokené™åˆ¶æˆ–ç½‘ç»œé—®é¢˜å¯¼è‡´è¾“å‡ºä¸å®Œæ•´ã€‚

```python
from agently_format.core.json_completer import JSONCompleter, CompletionStrategy
import json

def handle_incomplete_llm_output():
    """å¤„ç†å¤§æ¨¡å‹ä¸å®Œæ•´JSONè¾“å‡ºçš„æœ€ä½³å®è·µ"""
    completer = JSONCompleter()
    
    # æ¨¡æ‹Ÿå¤§æ¨¡å‹ä¸å®Œæ•´è¾“å‡º
    incomplete_outputs = [
        '{"users": [{"name": "Alice", "age": 25}, {"name": "Bob"',  # ç¼ºå°‘ç»“æŸæ‹¬å·
        '{"products": [{"id": 1, "name": "iPhone", "price": 999',    # ç¼ºå°‘å­—æ®µå’Œæ‹¬å·
        '{"data": {"total": 100, "items": [1, 2, 3',                # æ•°ç»„æœªé—­åˆ
    ]
    
    for i, incomplete_json in enumerate(incomplete_outputs):
        print(f"\n=== å¤„ç†ç¬¬{i+1}ä¸ªä¸å®Œæ•´JSON ===")
        print(f"åŸå§‹è¾“å‡º: {incomplete_json}")
        
        # ä½¿ç”¨æ™ºèƒ½ç­–ç•¥è¡¥å…¨
        result = completer.complete(
            incomplete_json, 
            strategy=CompletionStrategy.SMART
        )
        
        if result.is_valid:
            print(f"è¡¥å…¨æˆåŠŸ: {result.completed_json}")
            print(f"ç½®ä¿¡åº¦: {result.confidence:.2f}")
            
            # éªŒè¯è¡¥å…¨ç»“æœ
            try:
                parsed_data = json.loads(result.completed_json)
                print(f"è§£ææˆåŠŸ: {parsed_data}")
            except json.JSONDecodeError as e:
                print(f"è§£æå¤±è´¥: {e}")
        else:
            print(f"è¡¥å…¨å¤±è´¥: {result.error_message}")
            
            # å°è¯•ä¿å®ˆç­–ç•¥
            conservative_result = completer.complete(
                incomplete_json, 
                strategy=CompletionStrategy.CONSERVATIVE
            )
            if conservative_result.is_valid:
                print(f"ä¿å®ˆç­–ç•¥æˆåŠŸ: {conservative_result.completed_json}")

# è¿è¡Œç¤ºä¾‹
handle_incomplete_llm_output()
```

### åº”ç”¨åœºæ™¯2ï¼šæ‰¹é‡æ•°æ®æ¸…æ´—

**åœºæ™¯æè¿°**ï¼šä»æ—¥å¿—æ–‡ä»¶æˆ–APIå“åº”ä¸­æå–çš„JSONæ•°æ®ç»å¸¸æ ¼å¼ä¸å®Œæ•´ï¼Œéœ€è¦æ‰¹é‡å¤„ç†ã€‚

```python
from agently_format.core.json_completer import JSONCompleter
from typing import List, Dict, Any
import json
import logging

class JSONDataCleaner:
    """JSONæ•°æ®æ¸…æ´—å™¨"""
    
    def __init__(self):
        self.completer = JSONCompleter()
        self.logger = logging.getLogger(__name__)
    
    def clean_batch(self, json_strings: List[str]) -> Dict[str, Any]:
        """æ‰¹é‡æ¸…æ´—JSONæ•°æ®"""
        results = {
            "success": [],
            "failed": [],
            "statistics": {
                "total": len(json_strings),
                "success_count": 0,
                "failed_count": 0,
                "average_confidence": 0.0
            }
        }
        
        total_confidence = 0.0
        
        for i, json_str in enumerate(json_strings):
            try:
                # å°è¯•è¡¥å…¨
                completion_result = self.completer.complete(json_str)
                
                if completion_result.is_valid:
                    # éªŒè¯JSONæ ¼å¼
                    parsed_data = json.loads(completion_result.completed_json)
                    
                    results["success"].append({
                        "index": i,
                        "original": json_str,
                        "completed": completion_result.completed_json,
                        "parsed_data": parsed_data,
                        "confidence": completion_result.confidence
                    })
                    
                    total_confidence += completion_result.confidence
                    results["statistics"]["success_count"] += 1
                    
                else:
                    results["failed"].append({
                        "index": i,
                        "original": json_str,
                        "error": completion_result.error_message
                    })
                    results["statistics"]["failed_count"] += 1
                    
            except Exception as e:
                self.logger.error(f"å¤„ç†ç¬¬{i}ä¸ªJSONæ—¶å‡ºé”™: {e}")
                results["failed"].append({
                    "index": i,
                    "original": json_str,
                    "error": str(e)
                })
                results["statistics"]["failed_count"] += 1
        
        # è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
        if results["statistics"]["success_count"] > 0:
            results["statistics"]["average_confidence"] = (
                total_confidence / results["statistics"]["success_count"]
            )
        
        return results

# ä½¿ç”¨ç¤ºä¾‹
def demo_batch_cleaning():
    """æ¼”ç¤ºæ‰¹é‡æ¸…æ´—åŠŸèƒ½"""
    cleaner = JSONDataCleaner()
    
    # æ¨¡æ‹Ÿä»æ—¥å¿—ä¸­æå–çš„ä¸å®Œæ•´JSON
    dirty_jsons = [
        '{"user_id": 123, "action": "login"',
        '{"product": {"id": 456, "name": "Laptop"',
        '{"order": {"total": 299.99, "items": [',
        'invalid json string',
        '{"status": "success", "data": {"count": 10}}',  # å®Œæ•´çš„JSON
    ]
    
    results = cleaner.clean_batch(dirty_jsons)
    
    print("=== æ‰¹é‡æ¸…æ´—ç»“æœ ===")
    print(f"æ€»æ•°: {results['statistics']['total']}")
    print(f"æˆåŠŸ: {results['statistics']['success_count']}")
    print(f"å¤±è´¥: {results['statistics']['failed_count']}")
    print(f"å¹³å‡ç½®ä¿¡åº¦: {results['statistics']['average_confidence']:.2f}")
    
    print("\n=== æˆåŠŸæ¡ˆä¾‹ ===")
    for item in results["success"]:
        print(f"ç´¢å¼•{item['index']}: {item['completed']}")
    
    print("\n=== å¤±è´¥æ¡ˆä¾‹ ===")
    for item in results["failed"]:
        print(f"ç´¢å¼•{item['index']}: {item['error']}")

# è¿è¡Œæ¼”ç¤º
demo_batch_cleaning()
```

### å¸¸è§é—®é¢˜è§£å†³

**é—®é¢˜1ï¼šè¡¥å…¨ç»“æœç½®ä¿¡åº¦ä½**
```python
def handle_low_confidence():
    """å¤„ç†ä½ç½®ä¿¡åº¦è¡¥å…¨ç»“æœ"""
    completer = JSONCompleter()
    
    incomplete_json = '{"complex": {"nested": {"data"'
    result = completer.complete(incomplete_json)
    
    if result.is_valid and result.confidence < 0.7:
        print("ç½®ä¿¡åº¦è¾ƒä½ï¼Œå°è¯•ä¸åŒç­–ç•¥")
        
        # å°è¯•ä¿å®ˆç­–ç•¥
        conservative_result = completer.complete(
            incomplete_json, 
            strategy=CompletionStrategy.CONSERVATIVE
        )
        
        if conservative_result.confidence > result.confidence:
            print(f"ä¿å®ˆç­–ç•¥æ›´å¥½: {conservative_result.completed_json}")
            return conservative_result
    
    return result
```

**é—®é¢˜2ï¼šå¤„ç†ç‰¹æ®Šå­—ç¬¦**
```python
def handle_special_characters():
    """å¤„ç†åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„JSON"""
    completer = JSONCompleter()
    
    # åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„ä¸å®Œæ•´JSON
    special_json = '{"message": "Hello\nWorld", "emoji": "ğŸ˜€"'
    
    result = completer.complete(special_json)
    
    if result.is_valid:
        # éªŒè¯ç‰¹æ®Šå­—ç¬¦æ˜¯å¦æ­£ç¡®å¤„ç†
        parsed = json.loads(result.completed_json)
        print(f"æ¶ˆæ¯: {parsed['message']}")
        print(f"è¡¨æƒ…: {parsed['emoji']}")
    
    return result
```

---

## ğŸŒŠ æµå¼JSONè§£ææœ€ä½³å®è·µ

### åº”ç”¨åœºæ™¯1ï¼šå®æ—¶å¤„ç†å¤§æ¨¡å‹æµå¼è¾“å‡º

**åœºæ™¯æè¿°**ï¼šå¤„ç†ChatGPTã€Claudeç­‰å¤§æ¨¡å‹çš„æµå¼JSONå“åº”ï¼Œå®æ—¶è§£æå¹¶å±•ç¤ºç»“æœã€‚

```python
import asyncio
from agently_format.core.streaming_parser import StreamingParser
from agently_format.core.event_system import get_global_emitter, EventType
import json

class RealTimeJSONProcessor:
    """å®æ—¶JSONå¤„ç†å™¨"""
    
    def __init__(self):
        self.parser = StreamingParser()
        self.emitter = get_global_emitter()
        self.setup_event_handlers()
    
    def setup_event_handlers(self):
        """è®¾ç½®äº‹ä»¶å¤„ç†å™¨"""
        @self.emitter.on(EventType.DELTA)
        async def on_parse_progress(event):
            print(f"è§£æè¿›åº¦: {event.data}")
        
        @self.emitter.on(EventType.ERROR)
        async def on_parse_error(event):
            print(f"è§£æé”™è¯¯: {event.data}")
        
        @self.emitter.on(EventType.COMPLETE)
        async def on_parse_complete(event):
            print(f"è§£æå®Œæˆ: {event.data}")
    
    async def process_llm_stream(self, chunks):
        """å¤„ç†å¤§æ¨¡å‹æµå¼è¾“å‡º"""
        session_id = self.parser.create_session()
        
        try:
            for i, chunk in enumerate(chunks):
                print(f"\n--- å¤„ç†å— {i+1}/{len(chunks)} ---")
                print(f"æ¥æ”¶åˆ°: {chunk}")
                
                # è§£æå½“å‰å—
                result = await self.parser.parse_chunk(
                    session_id=session_id,
                    chunk=chunk
                )
                
                # è·å–å½“å‰è§£æçŠ¶æ€
                state = self.parser.parsing_states.get(session_id)
                if state and state.current_data:
                    print(f"å½“å‰æ•°æ®: {json.dumps(state.current_data, ensure_ascii=False, indent=2)}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´å¯¹è±¡
                if result and hasattr(result, 'parsed_objects'):
                    for obj in result.parsed_objects:
                        print(f"å®Œæ•´å¯¹è±¡: {obj}")
            
            # è·å–æœ€ç»ˆç»“æœ
            final_data = self.parser.get_current_data(session_id)
            print(f"\n=== æœ€ç»ˆç»“æœ ===")
            print(json.dumps(final_data, ensure_ascii=False, indent=2))
            
            return final_data
            
        finally:
            # æ¸…ç†ä¼šè¯
            self.parser.cleanup_session(session_id)

# æ¨¡æ‹Ÿå¤§æ¨¡å‹æµå¼è¾“å‡º
async def simulate_llm_streaming():
    """æ¨¡æ‹Ÿå¤§æ¨¡å‹æµå¼è¾“å‡º"""
    processor = RealTimeJSONProcessor()
    
    # æ¨¡æ‹Ÿåˆ†å—æ¥æ”¶çš„JSONæ•°æ®
    chunks = [
        '{"response": {',
        '"users": [',
        '{"id": 1, "name": "Alice", "age": 25},',
        '{"id": 2, "name": "Bob", "age": 30}',
        '],',
        '"total": 2,',
        '"status": "success"',
        '}}'
    ]
    
    print("å¼€å§‹å¤„ç†æµå¼JSONæ•°æ®...")
    result = await processor.process_llm_stream(chunks)
    
    return result

# è¿è¡Œç¤ºä¾‹
asyncio.run(simulate_llm_streaming())
```

### åº”ç”¨åœºæ™¯2ï¼šå¤„ç†å¤§æ–‡ä»¶JSONæµ

**åœºæ™¯æè¿°**ï¼šå¤„ç†å¤§å‹JSONæ–‡ä»¶çš„æµå¼è¯»å–ï¼Œé¿å…å†…å­˜æº¢å‡ºã€‚

```python
import asyncio
import aiofiles
from agently_format.core.streaming_parser import StreamingParser
from typing import AsyncGenerator

class LargeFileProcessor:
    """å¤§æ–‡ä»¶æµå¼å¤„ç†å™¨"""
    
    def __init__(self, chunk_size: int = 8192):
        self.parser = StreamingParser()
        self.chunk_size = chunk_size
    
    async def read_file_chunks(self, file_path: str) -> AsyncGenerator[str, None]:
        """å¼‚æ­¥è¯»å–æ–‡ä»¶å—"""
        async with aiofiles.open(file_path, 'r', encoding='utf-8') as file:
            while True:
                chunk = await file.read(self.chunk_size)
                if not chunk:
                    break
                yield chunk
    
    async def process_large_json_file(self, file_path: str):
        """å¤„ç†å¤§å‹JSONæ–‡ä»¶"""
        session_id = self.parser.create_session()
        processed_objects = []
        
        try:
            print(f"å¼€å§‹å¤„ç†æ–‡ä»¶: {file_path}")
            
            async for chunk in self.read_file_chunks(file_path):
                result = await self.parser.parse_chunk(
                    session_id=session_id,
                    chunk=chunk
                )
                
                # å¤„ç†å®Œæ•´çš„å¯¹è±¡
                if result and hasattr(result, 'parsed_objects'):
                    for obj in result.parsed_objects:
                        processed_objects.append(obj)
                        print(f"å¤„ç†äº†å¯¹è±¡: {len(processed_objects)}")
                        
                        # å¯ä»¥åœ¨è¿™é‡Œè¿›è¡Œå®æ—¶å¤„ç†
                        await self.process_single_object(obj)
            
            # è·å–æœ€ç»ˆæ•°æ®
            final_data = self.parser.get_current_data(session_id)
            
            return {
                "processed_objects": processed_objects,
                "final_data": final_data,
                "total_count": len(processed_objects)
            }
            
        finally:
            self.parser.cleanup_session(session_id)
    
    async def process_single_object(self, obj):
        """å¤„ç†å•ä¸ªå¯¹è±¡"""
        # è¿™é‡Œå¯ä»¥æ·»åŠ å…·ä½“çš„ä¸šåŠ¡é€»è¾‘
        # ä¾‹å¦‚ï¼šæ•°æ®éªŒè¯ã€è½¬æ¢ã€å­˜å‚¨ç­‰
        if isinstance(obj, dict) and 'id' in obj:
            print(f"å¤„ç†IDä¸º {obj['id']} çš„å¯¹è±¡")

# åˆ›å»ºæµ‹è¯•æ–‡ä»¶
async def create_test_file():
    """åˆ›å»ºæµ‹è¯•ç”¨çš„å¤§JSONæ–‡ä»¶"""
    test_data = {
        "users": [
            {"id": i, "name": f"User{i}", "email": f"user{i}@example.com"}
            for i in range(1000)  # 1000ä¸ªç”¨æˆ·
        ],
        "metadata": {
            "total": 1000,
            "created_at": "2024-01-01T00:00:00Z"
        }
    }
    
    async with aiofiles.open("large_test.json", 'w', encoding='utf-8') as file:
        await file.write(json.dumps(test_data, ensure_ascii=False))
    
    print("æµ‹è¯•æ–‡ä»¶åˆ›å»ºå®Œæˆ: large_test.json")

# ä½¿ç”¨ç¤ºä¾‹
async def demo_large_file_processing():
    """æ¼”ç¤ºå¤§æ–‡ä»¶å¤„ç†"""
    # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
    await create_test_file()
    
    # å¤„ç†æ–‡ä»¶
    processor = LargeFileProcessor(chunk_size=1024)  # 1KBå—
    result = await processor.process_large_json_file("large_test.json")
    
    print(f"\n=== å¤„ç†ç»“æœ ===")
    print(f"å¤„ç†å¯¹è±¡æ•°: {result['total_count']}")
    print(f"æœ€ç»ˆæ•°æ®é”®: {list(result['final_data'].keys()) if result['final_data'] else 'None'}")

# è¿è¡Œæ¼”ç¤º
asyncio.run(demo_large_file_processing())
```

### åº”ç”¨åœºæ™¯3ï¼šWebSocketå®æ—¶æ•°æ®å¤„ç†

**åœºæ™¯æè¿°**ï¼šé€šè¿‡WebSocketæ¥æ”¶å®æ—¶JSONæ•°æ®æµï¼Œå¦‚è‚¡ç¥¨ä»·æ ¼ã€èŠå¤©æ¶ˆæ¯ç­‰ã€‚

```python
import asyncio
import websockets
import json
from agently_format.core.streaming_parser import StreamingParser
from typing import Dict, Any

class WebSocketJSONHandler:
    """WebSocket JSONå¤„ç†å™¨"""
    
    def __init__(self):
        self.parser = StreamingParser()
        self.active_sessions: Dict[str, str] = {}  # client_id -> session_id
    
    async def handle_client(self, websocket, path):
        """å¤„ç†WebSocketå®¢æˆ·ç«¯è¿æ¥"""
        client_id = f"client_{id(websocket)}"
        session_id = self.parser.create_session()
        self.active_sessions[client_id] = session_id
        
        print(f"å®¢æˆ·ç«¯ {client_id} è¿æ¥")
        
        try:
            async for message in websocket:
                await self.process_message(client_id, message, websocket)
        
        except websockets.exceptions.ConnectionClosed:
            print(f"å®¢æˆ·ç«¯ {client_id} æ–­å¼€è¿æ¥")
        
        finally:
            # æ¸…ç†ä¼šè¯
            if client_id in self.active_sessions:
                self.parser.cleanup_session(self.active_sessions[client_id])
                del self.active_sessions[client_id]
    
    async def process_message(self, client_id: str, message: str, websocket):
        """å¤„ç†æ¥æ”¶åˆ°çš„æ¶ˆæ¯"""
        session_id = self.active_sessions[client_id]
        
        try:
            # è§£æJSONå—
            result = await self.parser.parse_chunk(
                session_id=session_id,
                chunk=message
            )
            
            # è·å–å½“å‰æ•°æ®
            current_data = self.parser.get_current_data(session_id)
            
            # å‘é€è§£æç»“æœç»™å®¢æˆ·ç«¯
            response = {
                "type": "parse_result",
                "client_id": client_id,
                "data": current_data,
                "is_complete": self.is_complete_json(current_data)
            }
            
            await websocket.send(json.dumps(response, ensure_ascii=False))
            
        except Exception as e:
            error_response = {
                "type": "error",
                "client_id": client_id,
                "error": str(e)
            }
            await websocket.send(json.dumps(error_response))
    
    def is_complete_json(self, data) -> bool:
        """æ£€æŸ¥JSONæ˜¯å¦å®Œæ•´"""
        return data is not None and isinstance(data, (dict, list))
    
    async def start_server(self, host="localhost", port=8765):
        """å¯åŠ¨WebSocketæœåŠ¡å™¨"""
        print(f"å¯åŠ¨WebSocketæœåŠ¡å™¨: ws://{host}:{port}")
        
        async with websockets.serve(self.handle_client, host, port):
            await asyncio.Future()  # æ°¸è¿œè¿è¡Œ

# å®¢æˆ·ç«¯ç¤ºä¾‹
async def websocket_client_demo():
    """WebSocketå®¢æˆ·ç«¯æ¼”ç¤º"""
    uri = "ws://localhost:8765"
    
    # æ¨¡æ‹Ÿåˆ†å—å‘é€çš„JSONæ•°æ®
    chunks = [
        '{"stock_data": {',
        '"symbol": "AAPL",',
        '"price": 150.25,',
        '"volume": 1000000',
        '}}'
    ]
    
    async with websockets.connect(uri) as websocket:
        print("è¿æ¥åˆ°WebSocketæœåŠ¡å™¨")
        
        # å‘é€JSONå—
        for i, chunk in enumerate(chunks):
            print(f"å‘é€å— {i+1}: {chunk}")
            await websocket.send(chunk)
            
            # æ¥æ”¶å“åº”
            response = await websocket.recv()
            result = json.loads(response)
            print(f"æ”¶åˆ°å“åº”: {result}")
            
            await asyncio.sleep(0.5)  # æ¨¡æ‹Ÿå»¶è¿Ÿ

# è¿è¡ŒæœåŠ¡å™¨å’Œå®¢æˆ·ç«¯
async def demo_websocket_processing():
    """æ¼”ç¤ºWebSocketå¤„ç†"""
    handler = WebSocketJSONHandler()
    
    # å¯åŠ¨æœåŠ¡å™¨ï¼ˆåœ¨åå°ï¼‰
    server_task = asyncio.create_task(
        handler.start_server()
    )
    
    # ç­‰å¾…æœåŠ¡å™¨å¯åŠ¨
    await asyncio.sleep(1)
    
    # è¿è¡Œå®¢æˆ·ç«¯
    try:
        await websocket_client_demo()
    except Exception as e:
        print(f"å®¢æˆ·ç«¯é”™è¯¯: {e}")
    finally:
        server_task.cancel()

# æ³¨æ„ï¼šè¿™ä¸ªç¤ºä¾‹éœ€è¦åœ¨å®é™…ç¯å¢ƒä¸­è¿è¡Œ
# asyncio.run(demo_websocket_processing())
```

### å¸¸è§é—®é¢˜è§£å†³

**é—®é¢˜1ï¼šå†…å­˜ä½¿ç”¨è¿‡å¤š**
```python
def optimize_memory_usage():
    """ä¼˜åŒ–å†…å­˜ä½¿ç”¨"""
    # è®¾ç½®è¾ƒå°çš„ç¼“å†²åŒºå¤§å°
    parser = StreamingParser(
        max_chunk_size=4096,  # 4KB
        session_ttl=300       # 5åˆ†é’Ÿè¶…æ—¶
    )
    
    # å®šæœŸæ¸…ç†æ— ç”¨ä¼šè¯
    async def cleanup_sessions():
        while True:
            parser.cleanup_expired_sessions()
            await asyncio.sleep(60)  # æ¯åˆ†é’Ÿæ¸…ç†ä¸€æ¬¡
    
    return parser
```

**é—®é¢˜2ï¼šå¤„ç†æŸåçš„JSONå—**
```python
async def handle_corrupted_chunks():
    """å¤„ç†æŸåçš„JSONå—"""
    parser = StreamingParser()
    session_id = parser.create_session()
    
    corrupted_chunks = [
        '{"data": [',
        'corrupted_chunk_here',  # æŸåçš„å—
        '1, 2, 3]}'
    ]
    
    for chunk in corrupted_chunks:
        try:
            result = await parser.parse_chunk(session_id, chunk)
            print(f"å¤„ç†æˆåŠŸ: {result}")
        except Exception as e:
            print(f"å¤„ç†å¤±è´¥: {e}")
            # å¯ä»¥é€‰æ‹©è·³è¿‡æˆ–å°è¯•ä¿®å¤
            continue
```

---

## ğŸ—ºï¸ æ•°æ®è·¯å¾„æ„å»ºæœ€ä½³å®è·µ

### åº”ç”¨åœºæ™¯1ï¼šåŠ¨æ€è¡¨å•ç”Ÿæˆ

**åœºæ™¯æè¿°**ï¼šæ ¹æ®JSON SchemaåŠ¨æ€ç”Ÿæˆè¡¨å•ï¼Œéœ€è¦æå–æ‰€æœ‰å¯èƒ½çš„æ•°æ®è·¯å¾„ã€‚

```python
from agently_format.core.path_builder import PathBuilder, PathStyle
from typing import Dict, List, Any
import json

class DynamicFormGenerator:
    """åŠ¨æ€è¡¨å•ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.path_builder = PathBuilder()
    
    def generate_form_fields(self, schema_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æ ¹æ®æ•°æ®ç»“æ„ç”Ÿæˆè¡¨å•å­—æ®µ"""
        # æå–æ‰€æœ‰è·¯å¾„
        paths = self.path_builder.extract_parsing_key_orders(schema_data)
        
        form_fields = []
        
        for path in paths:
            # è·å–è·¯å¾„å¯¹åº”çš„å€¼
            success, value = self.path_builder.get_value_at_path(schema_data, path)
            
            if success:
                field_info = self.create_field_info(path, value)
                form_fields.append(field_info)
        
        return form_fields
    
    def create_field_info(self, path: str, value: Any) -> Dict[str, Any]:
        """åˆ›å»ºå­—æ®µä¿¡æ¯"""
        field_type = self.determine_field_type(value)
        
        return {
            "path": path,
            "label": self.path_to_label(path),
            "type": field_type,
            "default_value": value,
            "required": value is not None,
            "validation": self.get_validation_rules(field_type, value)
        }
    
    def determine_field_type(self, value: Any) -> str:
        """ç¡®å®šå­—æ®µç±»å‹"""
        if isinstance(value, bool):
            return "checkbox"
        elif isinstance(value, int):
            return "number"
        elif isinstance(value, float):
            return "decimal"
        elif isinstance(value, str):
            if "@" in value:
                return "email"
            elif len(value) > 100:
                return "textarea"
            else:
                return "text"
        elif isinstance(value, list):
            return "multiselect"
        elif isinstance(value, dict):
            return "object"
        else:
            return "text"
    
    def path_to_label(self, path: str) -> str:
        """å°†è·¯å¾„è½¬æ¢ä¸ºç”¨æˆ·å‹å¥½çš„æ ‡ç­¾"""
        # ç§»é™¤æ•°ç»„ç´¢å¼•
        clean_path = path.replace('[0]', '').replace('[1]', '').replace('[2]', '')
        
        # åˆ†å‰²è·¯å¾„å¹¶è½¬æ¢ä¸ºæ ‡é¢˜æ ¼å¼
        parts = clean_path.split('.')
        labels = []
        
        for part in parts:
            if part:
                # è½¬æ¢é©¼å³°å‘½åä¸ºç©ºæ ¼åˆ†éš”
                import re
                label = re.sub(r'([A-Z])', r' \1', part).strip()
                label = label.replace('_', ' ').title()
                labels.append(label)
        
        return ' > '.join(labels)
    
    def get_validation_rules(self, field_type: str, value: Any) -> Dict[str, Any]:
        """è·å–éªŒè¯è§„åˆ™"""
        rules = {}
        
        if field_type == "email":
            rules["pattern"] = r"^[\w\.-]+@[\w\.-]+\.\w+$"
        elif field_type == "number":
            if isinstance(value, int) and value > 0:
                rules["min"] = 0
        elif field_type == "text":
            if isinstance(value, str) and len(value) > 0:
                rules["minLength"] = 1
                rules["maxLength"] = 255
        
        return rules

# ä½¿ç”¨ç¤ºä¾‹
def demo_form_generation():
    """æ¼”ç¤ºåŠ¨æ€è¡¨å•ç”Ÿæˆ"""
    generator = DynamicFormGenerator()
    
    # ç¤ºä¾‹ç”¨æˆ·æ•°æ®ç»“æ„
    user_schema = {
        "personal_info": {
            "first_name": "John",
            "last_name": "Doe",
            "email": "john.doe@example.com",
            "age": 30,
            "is_active": True
        },
        "address": {
            "street": "123 Main St",
            "city": "New York",
            "zip_code": "10001",
            "country": "USA"
        },
        "preferences": {
            "languages": ["English", "Spanish"],
            "notifications": {
                "email": True,
                "sms": False
            }
        }
    }
    
    # ç”Ÿæˆè¡¨å•å­—æ®µ
    form_fields = generator.generate_form_fields(user_schema)
    
    print("=== åŠ¨æ€ç”Ÿæˆçš„è¡¨å•å­—æ®µ ===")
    for field in form_fields:
        print(f"è·¯å¾„: {field['path']}")
        print(f"æ ‡ç­¾: {field['label']}")
        print(f"ç±»å‹: {field['type']}")
        print(f"é»˜è®¤å€¼: {field['default_value']}")
        print(f"å¿…å¡«: {field['required']}")
        print(f"éªŒè¯è§„åˆ™: {field['validation']}")
        print("-" * 40)

# è¿è¡Œæ¼”ç¤º
demo_form_generation()
```

### åº”ç”¨åœºæ™¯2ï¼šæ•°æ®æ˜ å°„å’Œè½¬æ¢

**åœºæ™¯æè¿°**ï¼šåœ¨ä¸åŒç³»ç»Ÿé—´è¿›è¡Œæ•°æ®è¿ç§»æ—¶ï¼Œéœ€è¦å»ºç«‹å­—æ®µæ˜ å°„å…³ç³»ã€‚

```python
from agently_format.core.path_builder import PathBuilder, PathStyle
from typing import Dict, Any, List, Tuple

class DataMapper:
    """æ•°æ®æ˜ å°„å™¨"""
    
    def __init__(self):
        self.path_builder = PathBuilder()
        self.mapping_rules: Dict[str, str] = {}
    
    def create_mapping(self, source_data: Dict[str, Any], target_schema: Dict[str, Any]) -> Dict[str, str]:
        """åˆ›å»ºæºæ•°æ®åˆ°ç›®æ ‡ç»“æ„çš„æ˜ å°„"""
        source_paths = self.path_builder.extract_parsing_key_orders(source_data)
        target_paths = self.path_builder.extract_parsing_key_orders(target_schema)
        
        mapping = {}
        
        # æ™ºèƒ½åŒ¹é…è·¯å¾„
        for source_path in source_paths:
            best_match = self.find_best_match(source_path, target_paths)
            if best_match:
                mapping[source_path] = best_match
        
        return mapping
    
    def find_best_match(self, source_path: str, target_paths: List[str]) -> str:
        """æ‰¾åˆ°æœ€ä½³åŒ¹é…çš„ç›®æ ‡è·¯å¾„"""
        source_parts = source_path.split('.')
        best_score = 0
        best_match = None
        
        for target_path in target_paths:
            target_parts = target_path.split('.')
            score = self.calculate_similarity(source_parts, target_parts)
            
            if score > best_score:
                best_score = score
                best_match = target_path
        
        # åªè¿”å›ç›¸ä¼¼åº¦è¶…è¿‡é˜ˆå€¼çš„åŒ¹é…
        return best_match if best_score > 0.5 else None
    
    def calculate_similarity(self, source_parts: List[str], target_parts: List[str]) -> float:
        """è®¡ç®—è·¯å¾„ç›¸ä¼¼åº¦"""
        # ç®€å•çš„ç›¸ä¼¼åº¦è®¡ç®—ï¼šåŒ¹é…çš„éƒ¨åˆ†æ•°é‡ / æ€»éƒ¨åˆ†æ•°é‡
        matches = 0
        total = max(len(source_parts), len(target_parts))
        
        for i in range(min(len(source_parts), len(target_parts))):
            if source_parts[i].lower() == target_parts[i].lower():
                matches += 1
            elif self.is_similar_field(source_parts[i], target_parts[i]):
                matches += 0.5
        
        return matches / total if total > 0 else 0
    
    def is_similar_field(self, field1: str, field2: str) -> bool:
        """æ£€æŸ¥å­—æ®µåæ˜¯å¦ç›¸ä¼¼"""
        # å¸¸è§çš„å­—æ®µåæ˜ å°„
        similar_fields = {
            "name": ["full_name", "username", "display_name"],
            "email": ["email_address", "mail"],
            "phone": ["phone_number", "mobile", "tel"],
            "address": ["addr", "location"],
            "id": ["identifier", "uid", "user_id"]
        }
        
        field1_lower = field1.lower()
        field2_lower = field2.lower()
        
        for key, variants in similar_fields.items():
            if (field1_lower == key and field2_lower in variants) or \
               (field2_lower == key and field1_lower in variants):
                return True
        
        return False
    
    def transform_data(self, source_data: Dict[str, Any], mapping: Dict[str, str]) -> Dict[str, Any]:
        """æ ¹æ®æ˜ å°„è§„åˆ™è½¬æ¢æ•°æ®"""
        result = {}
        
        for source_path, target_path in mapping.items():
            # è·å–æºæ•°æ®å€¼
            success, value = self.path_builder.get_value_at_path(source_data, source_path)
            
            if success and value is not None:
                # è®¾ç½®ç›®æ ‡è·¯å¾„çš„å€¼
                self.set_value_at_path(result, target_path, value)
        
        return result
    
    def set_value_at_path(self, data: Dict[str, Any], path: str, value: Any):
        """åœ¨æŒ‡å®šè·¯å¾„è®¾ç½®å€¼"""
        parts = path.split('.')
        current = data
        
        # åˆ›å»ºåµŒå¥—ç»“æ„
        for part in parts[:-1]:
            if part not in current:
                current[part] = {}
            current = current[part]
        
        # è®¾ç½®æœ€ç»ˆå€¼
        current[parts[-1]] = value

# ä½¿ç”¨ç¤ºä¾‹
def demo_data_mapping():
    """æ¼”ç¤ºæ•°æ®æ˜ å°„åŠŸèƒ½"""
    mapper = DataMapper()
    
    # æºç³»ç»Ÿæ•°æ®ç»“æ„
    source_data = {
        "user_info": {
            "full_name": "John Doe",
            "email_address": "john@example.com",
            "phone_number": "+1234567890"
        },
        "profile": {
            "age": 30,
            "location": {
                "city": "New York",
                "country": "USA"
            }
        }
    }
    
    # ç›®æ ‡ç³»ç»Ÿæ•°æ®ç»“æ„
    target_schema = {
        "personal": {
            "name": "",
            "email": "",
            "phone": ""
        },
        "demographics": {
            "age": 0,
            "address": {
                "city": "",
                "country": ""
            }
        }
    }
    
    # åˆ›å»ºæ˜ å°„
    mapping = mapper.create_mapping(source_data, target_schema)
    
    print("=== è‡ªåŠ¨ç”Ÿæˆçš„æ˜ å°„è§„åˆ™ ===")
    for source_path, target_path in mapping.items():
        print(f"{source_path} -> {target_path}")
    
    # è½¬æ¢æ•°æ®
    transformed_data = mapper.transform_data(source_data, mapping)
    
    print("\n=== è½¬æ¢åçš„æ•°æ® ===")
    print(json.dumps(transformed_data, indent=2, ensure_ascii=False))

# è¿è¡Œæ¼”ç¤º
demo_data_mapping()
```

### åº”ç”¨åœºæ™¯3ï¼šé…ç½®æ–‡ä»¶éªŒè¯

**åœºæ™¯æè¿°**ï¼šéªŒè¯å¤æ‚é…ç½®æ–‡ä»¶çš„ç»“æ„å’Œå¿…éœ€å­—æ®µã€‚

```python
from agently_format.core.path_builder import PathBuilder
from typing import Dict, Any, List, Set

class ConfigValidator:
    """é…ç½®æ–‡ä»¶éªŒè¯å™¨"""
    
    def __init__(self):
        self.path_builder = PathBuilder()
        self.required_paths: Set[str] = set()
        self.validation_rules: Dict[str, callable] = {}
    
    def add_required_path(self, path: str):
        """æ·»åŠ å¿…éœ€è·¯å¾„"""
        self.required_paths.add(path)
    
    def add_validation_rule(self, path: str, validator: callable):
        """æ·»åŠ éªŒè¯è§„åˆ™"""
        self.validation_rules[path] = validator
    
    def validate_config(self, config_data: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯é…ç½®æ–‡ä»¶"""
        result = {
            "is_valid": True,
            "errors": [],
            "warnings": [],
            "missing_required": [],
            "extra_fields": []
        }
        
        # æå–é…ç½®ä¸­çš„æ‰€æœ‰è·¯å¾„
        actual_paths = set(self.path_builder.extract_parsing_key_orders(config_data))
        
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        missing_required = self.required_paths - actual_paths
        if missing_required:
            result["missing_required"] = list(missing_required)
            result["errors"].extend([
                f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {path}" for path in missing_required
            ])
            result["is_valid"] = False
        
        # æ£€æŸ¥é¢å¤–å­—æ®µï¼ˆå¯é€‰ï¼‰
        if hasattr(self, 'allowed_paths'):
            extra_fields = actual_paths - self.allowed_paths - self.required_paths
            if extra_fields:
                result["extra_fields"] = list(extra_fields)
                result["warnings"].extend([
                    f"æœªçŸ¥å­—æ®µ: {path}" for path in extra_fields
                ])
        
        # æ‰§è¡Œè‡ªå®šä¹‰éªŒè¯è§„åˆ™
        for path, validator in self.validation_rules.items():
            if path in actual_paths:
                success, value = self.path_builder.get_value_at_path(config_data, path)
                if success:
                    try:
                        is_valid, error_msg = validator(value)
                        if not is_valid:
                            result["errors"].append(f"{path}: {error_msg}")
                            result["is_valid"] = False
                    except Exception as e:
                        result["errors"].append(f"{path}: éªŒè¯è§„åˆ™æ‰§è¡Œå¤±è´¥ - {e}")
                        result["is_valid"] = False
        
        return result

# éªŒè¯è§„åˆ™ç¤ºä¾‹
def validate_port(value) -> Tuple[bool, str]:
    """éªŒè¯ç«¯å£å·"""
    if not isinstance(value, int):
        return False, "ç«¯å£å·å¿…é¡»æ˜¯æ•´æ•°"
    if not (1 <= value <= 65535):
        return False, "ç«¯å£å·å¿…é¡»åœ¨1-65535ä¹‹é—´"
    return True, ""

def validate_email(value) -> Tuple[bool, str]:
    """éªŒè¯é‚®ç®±åœ°å€"""
    import re
    if not isinstance(value, str):
        return False, "é‚®ç®±åœ°å€å¿…é¡»æ˜¯å­—ç¬¦ä¸²"
    pattern = r'^[\w\.-]+@[\w\.-]+\.\w+$'
    if not re.match(pattern, value):
        return False, "é‚®ç®±åœ°å€æ ¼å¼ä¸æ­£ç¡®"
    return True, ""

def validate_url(value) -> Tuple[bool, str]:
    """éªŒè¯URL"""
    if not isinstance(value, str):
        return False, "URLå¿…é¡»æ˜¯å­—ç¬¦ä¸²"
    if not (value.startswith('http://') or value.startswith('https://')):
        return False, "URLå¿…é¡»ä»¥http://æˆ–https://å¼€å¤´"
    return True, ""

# ä½¿ç”¨ç¤ºä¾‹
def demo_config_validation():
    """æ¼”ç¤ºé…ç½®éªŒè¯åŠŸèƒ½"""
    validator = ConfigValidator()
    
    # è®¾ç½®å¿…éœ€å­—æ®µ
    validator.add_required_path("server.host")
    validator.add_required_path("server.port")
    validator.add_required_path("database.url")
    validator.add_required_path("admin.email")
    
    # è®¾ç½®éªŒè¯è§„åˆ™
    validator.add_validation_rule("server.port", validate_port)
    validator.add_validation_rule("admin.email", validate_email)
    validator.add_validation_rule("database.url", validate_url)
    
    # æµ‹è¯•é…ç½®1ï¼šå®Œæ•´ä¸”æ­£ç¡®çš„é…ç½®
    valid_config = {
        "server": {
            "host": "0.0.0.0",
            "port": 8000,
            "debug": False
        },
        "database": {
            "url": "https://db.example.com",
            "timeout": 30
        },
        "admin": {
            "email": "admin@example.com",
            "name": "Administrator"
        }
    }
    
    print("=== éªŒè¯æ­£ç¡®é…ç½® ===")
    result = validator.validate_config(valid_config)
    print(f"éªŒè¯ç»“æœ: {'é€šè¿‡' if result['is_valid'] else 'å¤±è´¥'}")
    if result['errors']:
        print(f"é”™è¯¯: {result['errors']}")
    if result['warnings']:
        print(f"è­¦å‘Š: {result['warnings']}")
    
    # æµ‹è¯•é…ç½®2ï¼šæœ‰é—®é¢˜çš„é…ç½®
    invalid_config = {
        "server": {
            "host": "0.0.0.0",
            "port": "invalid_port"  # é”™è¯¯ï¼šåº”è¯¥æ˜¯æ•´æ•°
        },
        "database": {
            "url": "invalid_url"  # é”™è¯¯ï¼šURLæ ¼å¼ä¸æ­£ç¡®
        },
        "admin": {
            "email": "invalid_email"  # é”™è¯¯ï¼šé‚®ç®±æ ¼å¼ä¸æ­£ç¡®
        }
        # ç¼ºå°‘å¿…éœ€å­—æ®µ
    }
    
    print("\n=== éªŒè¯é”™è¯¯é…ç½® ===")
    result = validator.validate_config(invalid_config)
    print(f"éªŒè¯ç»“æœ: {'é€šè¿‡' if result['is_valid'] else 'å¤±è´¥'}")
    if result['errors']:
        print("é”™è¯¯:")
        for error in result['errors']:
            print(f"  - {error}")
    if result['missing_required']:
        print(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {result['missing_required']}")

# è¿è¡Œæ¼”ç¤º
demo_config_validation()
```

### å¸¸è§é—®é¢˜è§£å†³

**é—®é¢˜1ï¼šå¤„ç†æ•°ç»„ç´¢å¼•**
```python
def handle_array_paths():
    """å¤„ç†æ•°ç»„è·¯å¾„"""
    builder = PathBuilder()
    
    data = {
        "users": [
            {"name": "Alice", "age": 25},
            {"name": "Bob", "age": 30}
        ]
    }
    
    # æå–è·¯å¾„æ—¶ä¼šåŒ…å«æ•°ç»„ç´¢å¼•
    paths = builder.extract_parsing_key_orders(data)
    print("åŒ…å«ç´¢å¼•çš„è·¯å¾„:", paths)
    
    # è·å–ä¸åŒ…å«ç´¢å¼•çš„é€šç”¨è·¯å¾„
    generic_paths = []
    for path in paths:
        # ç§»é™¤æ•°ç»„ç´¢å¼•
        generic_path = re.sub(r'\[\d+\]', '[]', path)
        if generic_path not in generic_paths:
            generic_paths.append(generic_path)
    
    print("é€šç”¨è·¯å¾„:", generic_paths)
```

**é—®é¢˜2ï¼šè·¯å¾„æ ¼å¼è½¬æ¢**
```python
def convert_path_formats():
    """è½¬æ¢è·¯å¾„æ ¼å¼"""
    builder = PathBuilder()
    
    original_path = "user.profile.settings[0].value"
    
    # è½¬æ¢ä¸ºä¸åŒæ ¼å¼
    slash_path = builder.convert_path(original_path, PathStyle.SLASH)
    bracket_path = builder.convert_path(original_path, PathStyle.BRACKET)
    
    print(f"åŸå§‹è·¯å¾„: {original_path}")
    print(f"æ–œæ æ ¼å¼: {slash_path}")
    print(f"æ‹¬å·æ ¼å¼: {bracket_path}")
```

---

## âœ… SchemaéªŒè¯æœ€ä½³å®è·µ

### åº”ç”¨åœºæ™¯1ï¼šAPIè¯·æ±‚éªŒè¯

**åœºæ™¯æè¿°**ï¼šéªŒè¯APIè¯·æ±‚æ•°æ®çš„æ ¼å¼å’Œå†…å®¹ï¼Œç¡®ä¿æ•°æ®å®Œæ•´æ€§å’Œå®‰å…¨æ€§ã€‚

```python
from agently_format.core.schemas import SchemaValidator
from pydantic import BaseModel, Field, validator
from typing import List, Optional, Dict, Any
from datetime import datetime
import re

# å®šä¹‰APIè¯·æ±‚æ¨¡å‹
class UserCreateRequest(BaseModel):
    """ç”¨æˆ·åˆ›å»ºè¯·æ±‚æ¨¡å‹"""
    username: str = Field(..., min_length=3, max_length=50)
    email: str = Field(..., regex=r'^[\w\.-]+@[\w\.-]+\.\w+$')
    password: str = Field(..., min_length=8)
    full_name: str = Field(..., min_length=1, max_length=100)
    age: Optional[int] = Field(None, ge=13, le=120)
    tags: List[str] = Field(default_factory=list)
    metadata: Optional[Dict[str, Any]] = None
    
    @validator('username')
    def validate_username(cls, v):
        if not re.match(r'^[a-zA-Z0-9_]+$', v):
            raise ValueError('ç”¨æˆ·ååªèƒ½åŒ…å«å­—æ¯ã€æ•°å­—å’Œä¸‹åˆ’çº¿')
        return v
    
    @validator('password')
    def validate_password(cls, v):
        if not re.search(r'[A-Z]', v):
            raise ValueError('å¯†ç å¿…é¡»åŒ…å«è‡³å°‘ä¸€ä¸ªå¤§å†™å­—æ¯')
        if not re.search(r'[a-z]', v):
            raise ValueError('å¯†ç å¿…é¡»åŒ…å«è‡³å°‘ä¸€ä¸ªå°å†™å­—æ¯')
        if not re.search(r'\d', v):
            raise ValueError('å¯†ç å¿…é¡»åŒ…å«è‡³å°‘ä¸€ä¸ªæ•°å­—')
        return v

class APIRequestValidator:
    """APIè¯·æ±‚éªŒè¯å™¨"""
    
    def __init__(self):
        self.user_validator = SchemaValidator(UserCreateRequest)
    
    def validate_user_creation(self, request_data: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯ç”¨æˆ·åˆ›å»ºè¯·æ±‚"""
        result = {
            "is_valid": False,
            "validated_data": None,
            "errors": [],
            "warnings": []
        }
        
        try:
            # æ‰§è¡ŒSchemaéªŒè¯
            validation_result = self.user_validator.validate(request_data)
            
            if validation_result.is_valid:
                result["is_valid"] = True
                result["validated_data"] = validation_result.validated_data
                
                # æ·»åŠ ä¸šåŠ¡é€»è¾‘éªŒè¯
                business_validation = self.validate_business_rules(request_data)
                if business_validation["warnings"]:
                    result["warnings"] = business_validation["warnings"]
                
            else:
                result["errors"] = [
                    {"field": error.path, "message": error.message}
                    for error in validation_result.errors
                ]
        
        except Exception as e:
            result["errors"] = [{"field": "general", "message": str(e)}]
        
        return result
    
    def validate_business_rules(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯ä¸šåŠ¡è§„åˆ™"""
        warnings = []
        
        # æ£€æŸ¥å¸¸è§çš„ä¸å®‰å…¨ç”¨æˆ·å
        unsafe_usernames = ['admin', 'root', 'administrator', 'test']
        if data.get('username', '').lower() in unsafe_usernames:
            warnings.append("å»ºè®®é¿å…ä½¿ç”¨å¸¸è§çš„ç³»ç»Ÿç”¨æˆ·å")
        
        # æ£€æŸ¥é‚®ç®±åŸŸå
        email = data.get('email', '')
        if email:
            domain = email.split('@')[-1]
            suspicious_domains = ['tempmail.com', '10minutemail.com']
            if domain in suspicious_domains:
                warnings.append("æ£€æµ‹åˆ°ä¸´æ—¶é‚®ç®±åŸŸå")
        
        # æ£€æŸ¥å¹´é¾„åˆç†æ€§
        age = data.get('age')
        if age and age < 16:
            warnings.append("ç”¨æˆ·å¹´é¾„è¾ƒå°ï¼Œå¯èƒ½éœ€è¦ç›‘æŠ¤äººåŒæ„")
        
        return {"warnings": warnings}

# ä½¿ç”¨ç¤ºä¾‹
def demo_api_validation():
    """æ¼”ç¤ºAPIéªŒè¯åŠŸèƒ½"""
    validator = APIRequestValidator()
    
    # æµ‹è¯•æ•°æ®1ï¼šæœ‰æ•ˆè¯·æ±‚
    valid_request = {
        "username": "john_doe",
        "email": "john@example.com",
        "password": "SecurePass123",
        "full_name": "John Doe",
        "age": 25,
        "tags": ["developer", "python"]
    }
    
    print("=== éªŒè¯æœ‰æ•ˆè¯·æ±‚ ===")
    result = validator.validate_user_creation(valid_request)
    print(f"éªŒè¯ç»“æœ: {'é€šè¿‡' if result['is_valid'] else 'å¤±è´¥'}")
    if result['warnings']:
        print(f"è­¦å‘Š: {result['warnings']}")
    
    # æµ‹è¯•æ•°æ®2ï¼šæ— æ•ˆè¯·æ±‚
    invalid_request = {
        "username": "a",  # å¤ªçŸ­
        "email": "invalid-email",  # æ ¼å¼é”™è¯¯
        "password": "weak",  # ä¸ç¬¦åˆå¯†ç è§„åˆ™
        "full_name": "",  # ç©ºå€¼
        "age": 200  # è¶…å‡ºèŒƒå›´
    }
    
    print("\n=== éªŒè¯æ— æ•ˆè¯·æ±‚ ===")
    result = validator.validate_user_creation(invalid_request)
    print(f"éªŒè¯ç»“æœ: {'é€šè¿‡' if result['is_valid'] else 'å¤±è´¥'}")
    if result['errors']:
        print("é”™è¯¯è¯¦æƒ…:")
        for error in result['errors']:
            print(f"  {error['field']}: {error['message']}")

# è¿è¡Œæ¼”ç¤º
demo_api_validation()
```

### åº”ç”¨åœºæ™¯2ï¼šé…ç½®æ–‡ä»¶éªŒè¯

**åœºæ™¯æè¿°**ï¼šéªŒè¯åº”ç”¨ç¨‹åºé…ç½®æ–‡ä»¶çš„ç»“æ„å’Œå€¼ï¼Œç¡®ä¿é…ç½®æ­£ç¡®ã€‚

```python
from agently_format.core.schemas import SchemaValidator
from pydantic import BaseModel, Field, validator
from typing import List, Optional, Dict, Union
import os

# å®šä¹‰é…ç½®æ¨¡å‹
class DatabaseConfig(BaseModel):
    """æ•°æ®åº“é…ç½®"""
    host: str = Field(..., min_length=1)
    port: int = Field(..., ge=1, le=65535)
    database: str = Field(..., min_length=1)
    username: str = Field(..., min_length=1)
    password: str = Field(..., min_length=1)
    pool_size: int = Field(default=10, ge=1, le=100)
    timeout: int = Field(default=30, ge=1, le=300)
    
    @validator('host')
    def validate_host(cls, v):
        # ç®€å•çš„ä¸»æœºåéªŒè¯
        if not (v == 'localhost' or '.' in v or ':' in v):
            raise ValueError('æ— æ•ˆçš„ä¸»æœºåæ ¼å¼')
        return v

class RedisConfig(BaseModel):
    """Redisé…ç½®"""
    host: str = Field(default='localhost')
    port: int = Field(default=6379, ge=1, le=65535)
    password: Optional[str] = None
    db: int = Field(default=0, ge=0, le=15)
    max_connections: int = Field(default=50, ge=1, le=1000)

class LoggingConfig(BaseModel):
    """æ—¥å¿—é…ç½®"""
    level: str = Field(..., regex=r'^(DEBUG|INFO|WARNING|ERROR|CRITICAL)$')
    format: str = Field(default='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    file_path: Optional[str] = None
    max_size: str = Field(default='10MB', regex=r'^\d+[KMGT]?B$')
    backup_count: int = Field(default=5, ge=1, le=100)
    
    @validator('file_path')
    def validate_file_path(cls, v):
        if v:
            directory = os.path.dirname(v)
            if directory and not os.path.exists(directory):
                raise ValueError(f'æ—¥å¿—ç›®å½•ä¸å­˜åœ¨: {directory}')
        return v

class ServerConfig(BaseModel):
    """æœåŠ¡å™¨é…ç½®"""
    host: str = Field(default='0.0.0.0')
    port: int = Field(..., ge=1, le=65535)
    workers: int = Field(default=1, ge=1, le=32)
    debug: bool = Field(default=False)
    secret_key: str = Field(..., min_length=32)
    
    @validator('secret_key')
    def validate_secret_key(cls, v):
        if len(set(v)) < 10:  # æ£€æŸ¥å­—ç¬¦å¤šæ ·æ€§
            raise ValueError('å¯†é’¥å­—ç¬¦å¤šæ ·æ€§ä¸è¶³')
        return v

class AppConfig(BaseModel):
    """åº”ç”¨ç¨‹åºé…ç½®"""
    app_name: str = Field(..., min_length=1)
    version: str = Field(..., regex=r'^\d+\.\d+\.\d+$')
    environment: str = Field(..., regex=r'^(development|staging|production)$')
    
    server: ServerConfig
    database: DatabaseConfig
    redis: Optional[RedisConfig] = None
    logging: LoggingConfig
    
    features: Dict[str, bool] = Field(default_factory=dict)
    external_apis: Dict[str, str] = Field(default_factory=dict)

class ConfigFileValidator:
    """é…ç½®æ–‡ä»¶éªŒè¯å™¨"""
    
    def __init__(self):
        self.validator = SchemaValidator(AppConfig)
        self.environment_checks = {
            'development': self.validate_dev_environment,
            'staging': self.validate_staging_environment,
            'production': self.validate_prod_environment
        }
    
    def validate_config_file(self, config_data: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯é…ç½®æ–‡ä»¶"""
        result = {
            "is_valid": False,
            "validated_data": None,
            "errors": [],
            "warnings": [],
            "security_issues": []
        }
        
        try:
            # åŸºç¡€SchemaéªŒè¯
            validation_result = self.validator.validate(config_data)
            
            if validation_result.is_valid:
                result["validated_data"] = validation_result.validated_data
                
                # ç¯å¢ƒç‰¹å®šéªŒè¯
                env = config_data.get('environment', 'development')
                if env in self.environment_checks:
                    env_result = self.environment_checks[env](config_data)
                    result["warnings"].extend(env_result.get('warnings', []))
                    result["security_issues"].extend(env_result.get('security_issues', []))
                
                # å®‰å…¨æ£€æŸ¥
                security_result = self.validate_security(config_data)
                result["security_issues"].extend(security_result)
                
                result["is_valid"] = True
            else:
                result["errors"] = [
                    {"field": error.path, "message": error.message}
                    for error in validation_result.errors
                ]
        
        except Exception as e:
            result["errors"] = [{"field": "general", "message": str(e)}]
        
        return result
    
    def validate_dev_environment(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯å¼€å‘ç¯å¢ƒé…ç½®"""
        warnings = []
        security_issues = []
        
        if not config.get('server', {}).get('debug', False):
            warnings.append("å¼€å‘ç¯å¢ƒå»ºè®®å¯ç”¨debugæ¨¡å¼")
        
        return {"warnings": warnings, "security_issues": security_issues}
    
    def validate_staging_environment(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯é¢„å‘å¸ƒç¯å¢ƒé…ç½®"""
        warnings = []
        security_issues = []
        
        if config.get('server', {}).get('debug', False):
            warnings.append("é¢„å‘å¸ƒç¯å¢ƒä¸å»ºè®®å¯ç”¨debugæ¨¡å¼")
        
        return {"warnings": warnings, "security_issues": security_issues}
    
    def validate_prod_environment(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯ç”Ÿäº§ç¯å¢ƒé…ç½®"""
        warnings = []
        security_issues = []
        
        server_config = config.get('server', {})
        
        if server_config.get('debug', False):
            security_issues.append("ç”Ÿäº§ç¯å¢ƒç¦æ­¢å¯ç”¨debugæ¨¡å¼")
        
        if server_config.get('host') == '0.0.0.0':
            warnings.append("ç”Ÿäº§ç¯å¢ƒå»ºè®®é™åˆ¶æœåŠ¡å™¨ç›‘å¬åœ°å€")
        
        # æ£€æŸ¥å¯†é’¥å¼ºåº¦
        secret_key = server_config.get('secret_key', '')
        if len(secret_key) < 64:
            security_issues.append("ç”Ÿäº§ç¯å¢ƒå¯†é’¥é•¿åº¦åº”è‡³å°‘64ä½")
        
        return {"warnings": warnings, "security_issues": security_issues}
    
    def validate_security(self, config: Dict[str, Any]) -> List[str]:
        """å®‰å…¨éªŒè¯"""
        issues = []
        
        # æ£€æŸ¥é»˜è®¤å¯†ç 
        db_config = config.get('database', {})
        if db_config.get('password') in ['password', '123456', 'admin']:
            issues.append("æ•°æ®åº“ä½¿ç”¨äº†å¼±å¯†ç ")
        
        # æ£€æŸ¥Rediså¯†ç 
        redis_config = config.get('redis', {})
        if redis_config and not redis_config.get('password'):
            issues.append("Redisæœªè®¾ç½®å¯†ç ")
        
        return issues

# ä½¿ç”¨ç¤ºä¾‹
def demo_config_validation():
    """æ¼”ç¤ºé…ç½®éªŒè¯åŠŸèƒ½"""
    validator = ConfigFileValidator()
    
    # æµ‹è¯•é…ç½®
    test_config = {
        "app_name": "MyApp",
        "version": "1.0.0",
        "environment": "production",
        "server": {
            "host": "0.0.0.0",
            "port": 8000,
            "workers": 4,
            "debug": False,
            "secret_key": "a_very_long_and_secure_secret_key_for_production_use_12345"
        },
        "database": {
            "host": "db.example.com",
            "port": 5432,
            "database": "myapp",
            "username": "dbuser",
            "password": "secure_password_123"
        },
        "logging": {
            "level": "INFO",
            "file_path": "/var/log/myapp.log"
        }
    }
    
    print("=== é…ç½®æ–‡ä»¶éªŒè¯ç»“æœ ===")
    result = validator.validate_config_file(test_config)
    
    print(f"éªŒè¯ç»“æœ: {'é€šè¿‡' if result['is_valid'] else 'å¤±è´¥'}")
    
    if result['errors']:
        print("\né”™è¯¯:")
        for error in result['errors']:
            print(f"  {error['field']}: {error['message']}")
    
    if result['warnings']:
        print("\nè­¦å‘Š:")
        for warning in result['warnings']:
            print(f"  - {warning}")
    
    if result['security_issues']:
        print("\nå®‰å…¨é—®é¢˜:")
        for issue in result['security_issues']:
            print(f"  âš ï¸ {issue}")

# è¿è¡Œæ¼”ç¤º
demo_config_validation()
```

### åº”ç”¨åœºæ™¯3ï¼šæ•°æ®å¯¼å…¥éªŒè¯

**åœºæ™¯æè¿°**ï¼šæ‰¹é‡å¯¼å…¥æ•°æ®æ—¶éªŒè¯æ¯æ¡è®°å½•çš„æ ¼å¼å’Œå†…å®¹ã€‚

```python
from agently_format.core.schemas import SchemaValidator
from pydantic import BaseModel, Field, validator
from typing import List, Dict, Any, Optional
from datetime import datetime, date
import csv
import json

# å®šä¹‰æ•°æ®æ¨¡å‹
class EmployeeRecord(BaseModel):
    """å‘˜å·¥è®°å½•æ¨¡å‹"""
    employee_id: str = Field(..., regex=r'^EMP\d{6}$')
    first_name: str = Field(..., min_length=1, max_length=50)
    last_name: str = Field(..., min_length=1, max_length=50)
    email: str = Field(..., regex=r'^[\w\.-]+@[\w\.-]+\.\w+$')
    department: str = Field(..., min_length=1)
    position: str = Field(..., min_length=1)
    hire_date: date
    salary: float = Field(..., gt=0, le=1000000)
    is_active: bool = Field(default=True)
    manager_id: Optional[str] = Field(None, regex=r'^EMP\d{6}$')
    
    @validator('hire_date')
    def validate_hire_date(cls, v):
        if v > date.today():
            raise ValueError('å…¥èŒæ—¥æœŸä¸èƒ½æ˜¯æœªæ¥æ—¥æœŸ')
        if v < date(1950, 1, 1):
            raise ValueError('å…¥èŒæ—¥æœŸè¿‡æ—©')
        return v
    
    @validator('email')
    def validate_email_domain(cls, v):
        allowed_domains = ['company.com', 'subsidiary.com']
        domain = v.split('@')[1]
        if domain not in allowed_domains:
            raise ValueError(f'é‚®ç®±åŸŸåå¿…é¡»æ˜¯: {", ".join(allowed_domains)}')
        return v

class DataImportValidator:
    """æ•°æ®å¯¼å…¥éªŒè¯å™¨"""
    
    def __init__(self):
        self.employee_validator = SchemaValidator(EmployeeRecord)
        self.processed_ids = set()
    
    def validate_batch_import(self, records: List[Dict[str, Any]]) -> Dict[str, Any]:
        """æ‰¹é‡éªŒè¯å¯¼å…¥æ•°æ®"""
        result = {
            "total_records": len(records),
            "valid_records": [],
            "invalid_records": [],
            "duplicate_ids": [],
            "summary": {
                "valid_count": 0,
                "invalid_count": 0,
                "duplicate_count": 0
            }
        }
        
        for i, record in enumerate(records):
            record_result = self.validate_single_record(record, i)
            
            if record_result["is_valid"]:
                # æ£€æŸ¥é‡å¤ID
                emp_id = record.get('employee_id')
                if emp_id in self.processed_ids:
                    result["duplicate_ids"].append({
                        "row": i + 1,
                        "employee_id": emp_id,
                        "error": "å‘˜å·¥IDé‡å¤"
                    })
                    result["summary"]["duplicate_count"] += 1
                else:
                    self.processed_ids.add(emp_id)
                    result["valid_records"].append({
                        "row": i + 1,
                        "data": record_result["validated_data"]
                    })
                    result["summary"]["valid_count"] += 1
            else:
                result["invalid_records"].append({
                    "row": i + 1,
                    "data": record,
                    "errors": record_result["errors"]
                })
                result["summary"]["invalid_count"] += 1
        
        return result
    
    def validate_single_record(self, record: Dict[str, Any], row_index: int) -> Dict[str, Any]:
        """éªŒè¯å•æ¡è®°å½•"""
        try:
            # æ•°æ®ç±»å‹è½¬æ¢
            processed_record = self.preprocess_record(record)
            
            # SchemaéªŒè¯
            validation_result = self.employee_validator.validate(processed_record)
            
            if validation_result.is_valid:
                return {
                    "is_valid": True,
                    "validated_data": validation_result.validated_data,
                    "errors": []
                }
            else:
                return {
                    "is_valid": False,
                    "validated_data": None,
                    "errors": [
                        {"field": error.path, "message": error.message}
                        for error in validation_result.errors
                    ]
                }
        
        except Exception as e:
            return {
                "is_valid": False,
                "validated_data": None,
                "errors": [{"field": "general", "message": str(e)}]
            }
    
    def preprocess_record(self, record: Dict[str, Any]) -> Dict[str, Any]:
        """é¢„å¤„ç†è®°å½•æ•°æ®"""
        processed = record.copy()
        
        # è½¬æ¢æ—¥æœŸæ ¼å¼
        if 'hire_date' in processed and isinstance(processed['hire_date'], str):
            try:
                processed['hire_date'] = datetime.strptime(
                    processed['hire_date'], '%Y-%m-%d'
                ).date()
            except ValueError:
                try:
                    processed['hire_date'] = datetime.strptime(
                        processed['hire_date'], '%m/%d/%Y'
                    ).date()
                except ValueError:
                    pass  # è®©SchemaéªŒè¯å¤„ç†é”™è¯¯
        
        # è½¬æ¢è–ªèµ„æ ¼å¼
        if 'salary' in processed and isinstance(processed['salary'], str):
            try:
                # ç§»é™¤è´§å¸ç¬¦å·å’Œé€—å·
                salary_str = processed['salary'].replace('$', '').replace(',', '')
                processed['salary'] = float(salary_str)
            except ValueError:
                pass  # è®©SchemaéªŒè¯å¤„ç†é”™è¯¯
        
        # è½¬æ¢å¸ƒå°”å€¼
        if 'is_active' in processed and isinstance(processed['is_active'], str):
            processed['is_active'] = processed['is_active'].lower() in ['true', '1', 'yes', 'y']
        
        return processed
    
    def generate_error_report(self, validation_result: Dict[str, Any]) -> str:
        """ç”Ÿæˆé”™è¯¯æŠ¥å‘Š"""
        report = []
        report.append("=== æ•°æ®å¯¼å…¥éªŒè¯æŠ¥å‘Š ===")
        report.append(f"æ€»è®°å½•æ•°: {validation_result['total_records']}")
        report.append(f"æœ‰æ•ˆè®°å½•: {validation_result['summary']['valid_count']}")
        report.append(f"æ— æ•ˆè®°å½•: {validation_result['summary']['invalid_count']}")
        report.append(f"é‡å¤è®°å½•: {validation_result['summary']['duplicate_count']}")
        report.append("")
        
        if validation_result['invalid_records']:
            report.append("=== æ— æ•ˆè®°å½•è¯¦æƒ… ===")
            for record in validation_result['invalid_records']:
                report.append(f"ç¬¬{record['row']}è¡Œ:")
                for error in record['errors']:
                    report.append(f"  {error['field']}: {error['message']}")
                report.append("")
        
        if validation_result['duplicate_ids']:
            report.append("=== é‡å¤IDè®°å½• ===")
            for dup in validation_result['duplicate_ids']:
                report.append(f"ç¬¬{dup['row']}è¡Œ: {dup['employee_id']} - {dup['error']}")
        
        return "\n".join(report)

# ä½¿ç”¨ç¤ºä¾‹
def demo_data_import_validation():
    """æ¼”ç¤ºæ•°æ®å¯¼å…¥éªŒè¯"""
    validator = DataImportValidator()
    
    # æ¨¡æ‹ŸCSVå¯¼å…¥æ•°æ®
    import_data = [
        {
            "employee_id": "EMP123456",
            "first_name": "John",
            "last_name": "Doe",
            "email": "john.doe@company.com",
            "department": "Engineering",
            "position": "Software Engineer",
            "hire_date": "2023-01-15",
            "salary": "75000.00",
            "is_active": "true"
        },
        {
            "employee_id": "EMP123457",
            "first_name": "Jane",
            "last_name": "Smith",
            "email": "jane.smith@external.com",  # é”™è¯¯ï¼šåŸŸåä¸å…è®¸
            "department": "Marketing",
            "position": "Marketing Manager",
            "hire_date": "2025-01-01",  # é”™è¯¯ï¼šæœªæ¥æ—¥æœŸ
            "salary": "invalid_salary",  # é”™è¯¯ï¼šæ— æ•ˆè–ªèµ„
            "is_active": "yes"
        },
        {
            "employee_id": "EMP123456",  # é”™è¯¯ï¼šé‡å¤ID
            "first_name": "Bob",
            "last_name": "Johnson",
            "email": "bob.johnson@company.com",
            "department": "Sales",
            "position": "Sales Representative",
            "hire_date": "2023-03-01",
            "salary": "60000",
            "is_active": "true"
        }
    ]
    
    # æ‰§è¡ŒéªŒè¯
    result = validator.validate_batch_import(import_data)
    
    # ç”ŸæˆæŠ¥å‘Š
    report = validator.generate_error_report(result)
    print(report)
    
    # è¾“å‡ºæœ‰æ•ˆè®°å½•
    if result['valid_records']:
        print("\n=== æœ‰æ•ˆè®°å½• ===")
        for record in result['valid_records']:
            print(f"ç¬¬{record['row']}è¡Œ: {record['data']['first_name']} {record['data']['last_name']}")

# è¿è¡Œæ¼”ç¤º
demo_data_import_validation()
```

### å¸¸è§é—®é¢˜è§£å†³æ–¹æ¡ˆ

**Q1: å¦‚ä½•å¤„ç†å¤§é‡æ•°æ®çš„éªŒè¯æ€§èƒ½é—®é¢˜ï¼Ÿ**

A1: ä½¿ç”¨æ‰¹é‡éªŒè¯å’Œç¼“å­˜ä¼˜åŒ–ï¼š

```python
from agently_format.core.schemas import SchemaValidator
from concurrent.futures import ThreadPoolExecutor
import time

class PerformanceOptimizedValidator:
    """æ€§èƒ½ä¼˜åŒ–çš„éªŒè¯å™¨"""
    
    def __init__(self, schema_class, batch_size=100, max_workers=4):
        self.validator = SchemaValidator(schema_class)
        self.batch_size = batch_size
        self.max_workers = max_workers
        self.validation_cache = {}
    
    def validate_large_dataset(self, records: List[Dict[str, Any]]) -> Dict[str, Any]:
        """éªŒè¯å¤§æ•°æ®é›†"""
        start_time = time.time()
        
        # åˆ†æ‰¹å¤„ç†
        batches = [records[i:i + self.batch_size] 
                  for i in range(0, len(records), self.batch_size)]
        
        all_results = []
        
        # å¹¶è¡Œå¤„ç†æ‰¹æ¬¡
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            batch_results = list(executor.map(self.validate_batch, batches))
        
        # åˆå¹¶ç»“æœ
        total_valid = sum(result['valid_count'] for result in batch_results)
        total_invalid = sum(result['invalid_count'] for result in batch_results)
        
        end_time = time.time()
        
        return {
            "total_records": len(records),
            "valid_count": total_valid,
            "invalid_count": total_invalid,
            "processing_time": end_time - start_time,
            "records_per_second": len(records) / (end_time - start_time)
        }
    
    def validate_batch(self, batch: List[Dict[str, Any]]) -> Dict[str, Any]:
        """éªŒè¯å•ä¸ªæ‰¹æ¬¡"""
        valid_count = 0
        invalid_count = 0
        
        for record in batch:
            # ä½¿ç”¨ç¼“å­˜åŠ é€Ÿé‡å¤éªŒè¯
            record_hash = hash(str(sorted(record.items())))
            
            if record_hash in self.validation_cache:
                is_valid = self.validation_cache[record_hash]
            else:
                result = self.validator.validate(record)
                is_valid = result.is_valid
                self.validation_cache[record_hash] = is_valid
            
            if is_valid:
                valid_count += 1
            else:
                invalid_count += 1
        
        return {"valid_count": valid_count, "invalid_count": invalid_count}
```

**Q2: å¦‚ä½•è‡ªå®šä¹‰å¤æ‚çš„éªŒè¯è§„åˆ™ï¼Ÿ**

A2: åˆ›å»ºè‡ªå®šä¹‰éªŒè¯å™¨ï¼š

```python
from agently_format.core.schemas import SchemaValidator
from pydantic import BaseModel, validator, root_validator
from typing import Dict, Any

class CustomBusinessRules(BaseModel):
    """è‡ªå®šä¹‰ä¸šåŠ¡è§„åˆ™æ¨¡å‹"""
    user_id: str
    account_type: str
    balance: float
    credit_limit: float
    
    @validator('balance')
    def validate_balance(cls, v, values):
        account_type = values.get('account_type')
        if account_type == 'savings' and v < 0:
            raise ValueError('å‚¨è“„è´¦æˆ·ä½™é¢ä¸èƒ½ä¸ºè´Ÿ')
        return v
    
    @root_validator
    def validate_credit_rules(cls, values):
        account_type = values.get('account_type')
        balance = values.get('balance')
        credit_limit = values.get('credit_limit')
        
        if account_type == 'credit':
            if balance < -credit_limit:
                raise ValueError('ä½™é¢ä¸èƒ½è¶…è¿‡ä¿¡ç”¨é¢åº¦')
        
        return values

class BusinessRuleValidator:
    """ä¸šåŠ¡è§„åˆ™éªŒè¯å™¨"""
    
    def __init__(self):
        self.validator = SchemaValidator(CustomBusinessRules)
        self.business_rules = {
            'vip_customer': self.validate_vip_rules,
            'corporate_account': self.validate_corporate_rules
        }
    
    def validate_with_business_context(self, data: Dict[str, Any], 
                                     context: Dict[str, Any]) -> Dict[str, Any]:
        """å¸¦ä¸šåŠ¡ä¸Šä¸‹æ–‡çš„éªŒè¯"""
        # åŸºç¡€SchemaéªŒè¯
        base_result = self.validator.validate(data)
        
        if not base_result.is_valid:
            return {
                "is_valid": False,
                "errors": [error.message for error in base_result.errors],
                "business_warnings": []
            }
        
        # ä¸šåŠ¡è§„åˆ™éªŒè¯
        business_warnings = []
        customer_type = context.get('customer_type')
        
        if customer_type in self.business_rules:
            warnings = self.business_rules[customer_type](data, context)
            business_warnings.extend(warnings)
        
        return {
            "is_valid": True,
            "validated_data": base_result.validated_data,
            "business_warnings": business_warnings
        }
    
    def validate_vip_rules(self, data: Dict[str, Any], 
                          context: Dict[str, Any]) -> List[str]:
        """VIPå®¢æˆ·è§„åˆ™éªŒè¯"""
        warnings = []
        
        if data['balance'] < 10000:
            warnings.append("VIPå®¢æˆ·ä½™é¢å»ºè®®ä¿æŒåœ¨1ä¸‡ä»¥ä¸Š")
        
        if data['account_type'] == 'basic':
            warnings.append("VIPå®¢æˆ·å»ºè®®å‡çº§åˆ°é«˜çº§è´¦æˆ·ç±»å‹")
        
        return warnings
    
    def validate_corporate_rules(self, data: Dict[str, Any], 
                               context: Dict[str, Any]) -> List[str]:
        """ä¼ä¸šå®¢æˆ·è§„åˆ™éªŒè¯"""
        warnings = []
        
        if data['credit_limit'] < 50000:
            warnings.append("ä¼ä¸šå®¢æˆ·å»ºè®®ç”³è¯·æ›´é«˜ä¿¡ç”¨é¢åº¦")
        
        return warnings
```

---

## 5. å·®åˆ†å¼•æ“æœ€ä½³å®è·µ

### æ ¸å¿ƒåŠŸèƒ½æ¦‚è¿°

å·®åˆ†å¼•æ“æä¾›é«˜æ•ˆçš„æ•°æ®å˜æ›´æ£€æµ‹å’ŒåŒæ­¥åŠŸèƒ½ï¼Œæ”¯æŒç»“æ„åŒ–å·®åˆ†ã€å¢é‡æ›´æ–°ã€ç‰ˆæœ¬è¿½è¸ªç­‰ç‰¹æ€§ã€‚

### åº”ç”¨åœºæ™¯1ï¼šç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿ

**åœºæ™¯æè¿°**ï¼šä¸ºé…ç½®æ–‡ä»¶æˆ–æ•°æ®ç»“æ„å®ç°ç‰ˆæœ¬æ§åˆ¶ï¼Œè¿½è¸ªå˜æ›´å†å²ã€‚

```python
from agently_format.core.diff import DiffEngine
from typing import Dict, Any, List
from datetime import datetime
import json
import uuid

class VersionControlSystem:
    """ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿ"""
    
    def __init__(self):
        self.diff_engine = DiffEngine()
        self.versions = {}  # version_id -> version_data
        self.version_history = []  # ç‰ˆæœ¬å†å²è®°å½•
        self.current_version = None
    
    def create_initial_version(self, data: Dict[str, Any], 
                             description: str = "Initial version") -> str:
        """åˆ›å»ºåˆå§‹ç‰ˆæœ¬"""
        version_id = str(uuid.uuid4())
        
        version_info = {
            "id": version_id,
            "data": data,
            "timestamp": datetime.now().isoformat(),
            "description": description,
            "parent_version": None,
            "changes": None
        }
        
        self.versions[version_id] = version_info
        self.version_history.append(version_id)
        self.current_version = version_id
        
        return version_id
    
    def create_new_version(self, new_data: Dict[str, Any], 
                          description: str = "New version") -> str:
        """åˆ›å»ºæ–°ç‰ˆæœ¬"""
        if not self.current_version:
            return self.create_initial_version(new_data, description)
        
        # è®¡ç®—ä¸å½“å‰ç‰ˆæœ¬çš„å·®å¼‚
        current_data = self.versions[self.current_version]["data"]
        diff_result = self.diff_engine.compute_diff(current_data, new_data)
        
        version_id = str(uuid.uuid4())
        
        version_info = {
            "id": version_id,
            "data": new_data,
            "timestamp": datetime.now().isoformat(),
            "description": description,
            "parent_version": self.current_version,
            "changes": diff_result
        }
        
        self.versions[version_id] = version_info
        self.version_history.append(version_id)
        self.current_version = version_id
        
        return version_id
    
    def get_version_diff(self, version_a: str, version_b: str) -> Dict[str, Any]:
        """è·å–ä¸¤ä¸ªç‰ˆæœ¬ä¹‹é—´çš„å·®å¼‚"""
        if version_a not in self.versions or version_b not in self.versions:
            raise ValueError("ç‰ˆæœ¬ä¸å­˜åœ¨")
        
        data_a = self.versions[version_a]["data"]
        data_b = self.versions[version_b]["data"]
        
        return self.diff_engine.compute_diff(data_a, data_b)
    
    def rollback_to_version(self, version_id: str) -> bool:
        """å›æ»šåˆ°æŒ‡å®šç‰ˆæœ¬"""
        if version_id not in self.versions:
            return False
        
        self.current_version = version_id
        return True
    
    def get_version_history(self) -> List[Dict[str, Any]]:
        """è·å–ç‰ˆæœ¬å†å²"""
        history = []
        
        for version_id in self.version_history:
            version_info = self.versions[version_id]
            
            # è®¡ç®—å˜æ›´ç»Ÿè®¡
            changes_summary = self.summarize_changes(version_info.get("changes"))
            
            history.append({
                "id": version_id,
                "timestamp": version_info["timestamp"],
                "description": version_info["description"],
                "parent_version": version_info["parent_version"],
                "changes_summary": changes_summary
            })
        
        return history
    
    def summarize_changes(self, changes: Dict[str, Any]) -> Dict[str, int]:
        """æ±‡æ€»å˜æ›´ç»Ÿè®¡"""
        if not changes:
            return {"added": 0, "modified": 0, "deleted": 0}
        
        summary = {"added": 0, "modified": 0, "deleted": 0}
        
        for change in changes.get("changes", []):
            change_type = change.get("type")
            if change_type == "add":
                summary["added"] += 1
            elif change_type == "modify":
                summary["modified"] += 1
            elif change_type == "delete":
                summary["deleted"] += 1
        
        return summary
    
    def export_version_tree(self) -> Dict[str, Any]:
        """å¯¼å‡ºç‰ˆæœ¬æ ‘ç»“æ„"""
        tree = {}
        
        for version_id in self.version_history:
            version_info = self.versions[version_id]
            parent = version_info["parent_version"]
            
            tree[version_id] = {
                "parent": parent,
                "timestamp": version_info["timestamp"],
                "description": version_info["description"],
                "is_current": version_id == self.current_version
            }
        
        return tree

# ä½¿ç”¨ç¤ºä¾‹
def demo_version_control():
    """æ¼”ç¤ºç‰ˆæœ¬æ§åˆ¶åŠŸèƒ½"""
    vcs = VersionControlSystem()
    
    # åˆ›å»ºåˆå§‹é…ç½®
    initial_config = {
        "app_name": "MyApp",
        "version": "1.0.0",
        "database": {
            "host": "localhost",
            "port": 5432,
            "name": "myapp_db"
        },
        "features": {
            "user_auth": True,
            "file_upload": False
        }
    }
    
    v1 = vcs.create_initial_version(initial_config, "åˆå§‹é…ç½®")
    print(f"åˆ›å»ºåˆå§‹ç‰ˆæœ¬: {v1}")
    
    # æ›´æ–°é…ç½® - æ·»åŠ æ–°åŠŸèƒ½
    updated_config = initial_config.copy()
    updated_config["version"] = "1.1.0"
    updated_config["features"]["file_upload"] = True
    updated_config["features"]["email_notifications"] = True
    
    v2 = vcs.create_new_version(updated_config, "å¯ç”¨æ–‡ä»¶ä¸Šä¼ å’Œé‚®ä»¶é€šçŸ¥")
    print(f"åˆ›å»ºç‰ˆæœ¬2: {v2}")
    
    # å†æ¬¡æ›´æ–° - ä¿®æ”¹æ•°æ®åº“é…ç½®
    final_config = updated_config.copy()
    final_config["version"] = "1.2.0"
    final_config["database"]["host"] = "prod-db.example.com"
    final_config["database"]["port"] = 5433
    
    v3 = vcs.create_new_version(final_config, "æ›´æ–°ç”Ÿäº§æ•°æ®åº“é…ç½®")
    print(f"åˆ›å»ºç‰ˆæœ¬3: {v3}")
    
    # æŸ¥çœ‹ç‰ˆæœ¬å†å²
    print("\n=== ç‰ˆæœ¬å†å² ===")
    history = vcs.get_version_history()
    for version in history:
        print(f"ç‰ˆæœ¬: {version['id'][:8]}...")
        print(f"  æ—¶é—´: {version['timestamp']}")
        print(f"  æè¿°: {version['description']}")
        print(f"  å˜æ›´: +{version['changes_summary']['added']} "
              f"~{version['changes_summary']['modified']} "
              f"-{version['changes_summary']['deleted']}")
        print()
    
    # æŸ¥çœ‹ç‰¹å®šç‰ˆæœ¬é—´çš„å·®å¼‚
    print("=== ç‰ˆæœ¬å·®å¼‚ (v1 -> v3) ===")
    diff = vcs.get_version_diff(v1, v3)
    print(json.dumps(diff, indent=2, ensure_ascii=False))
    
    # å›æ»šæ¼”ç¤º
    print(f"\nå½“å‰ç‰ˆæœ¬: {vcs.current_version[:8]}...")
    vcs.rollback_to_version(v2)
    print(f"å›æ»šåç‰ˆæœ¬: {vcs.current_version[:8]}...")

# è¿è¡Œæ¼”ç¤º
demo_version_control()
```

### åº”ç”¨åœºæ™¯2ï¼šæ•°æ®åŒæ­¥ç³»ç»Ÿ

**åœºæ™¯æè¿°**ï¼šåœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­åŒæ­¥æ•°æ®å˜æ›´ï¼Œå‡å°‘ç½‘ç»œä¼ è¾“é‡ã€‚

```python
from agently_format.core.diff import DiffEngine
from typing import Dict, Any, List, Optional
import json
import time
from datetime import datetime

class DataSyncManager:
    """æ•°æ®åŒæ­¥ç®¡ç†å™¨"""
    
    def __init__(self, node_id: str):
        self.node_id = node_id
        self.diff_engine = DiffEngine()
        self.local_data = {}
        self.sync_log = []  # åŒæ­¥æ—¥å¿—
        self.last_sync_time = {}
    
    def update_local_data(self, key: str, data: Dict[str, Any]) -> Dict[str, Any]:
        """æ›´æ–°æœ¬åœ°æ•°æ®å¹¶ç”Ÿæˆå·®åˆ†"""
        old_data = self.local_data.get(key, {})
        
        # è®¡ç®—å·®åˆ†
        diff_result = self.diff_engine.compute_diff(old_data, data)
        
        # æ›´æ–°æœ¬åœ°æ•°æ®
        self.local_data[key] = data
        
        # è®°å½•åŒæ­¥æ—¥å¿—
        sync_entry = {
            "timestamp": datetime.now().isoformat(),
            "node_id": self.node_id,
            "key": key,
            "operation": "update",
            "diff": diff_result,
            "data_size": len(json.dumps(data)),
            "diff_size": len(json.dumps(diff_result))
        }
        
        self.sync_log.append(sync_entry)
        
        return {
            "success": True,
            "diff": diff_result,
            "compression_ratio": sync_entry["diff_size"] / sync_entry["data_size"] if sync_entry["data_size"] > 0 else 0
        }
    
    def apply_remote_diff(self, key: str, diff: Dict[str, Any], 
                         source_node: str) -> Dict[str, Any]:
        """åº”ç”¨è¿œç¨‹èŠ‚ç‚¹çš„å·®åˆ†æ›´æ–°"""
        try:
            old_data = self.local_data.get(key, {})
            
            # åº”ç”¨å·®åˆ†
            new_data = self.diff_engine.apply_diff(old_data, diff)
            
            # æ›´æ–°æœ¬åœ°æ•°æ®
            self.local_data[key] = new_data
            
            # è®°å½•åŒæ­¥æ—¥å¿—
            sync_entry = {
                "timestamp": datetime.now().isoformat(),
                "node_id": self.node_id,
                "source_node": source_node,
                "key": key,
                "operation": "apply_diff",
                "diff": diff,
                "success": True
            }
            
            self.sync_log.append(sync_entry)
            self.last_sync_time[source_node] = datetime.now().isoformat()
            
            return {
                "success": True,
                "updated_data": new_data,
                "message": f"æˆåŠŸåº”ç”¨æ¥è‡ªèŠ‚ç‚¹ {source_node} çš„å·®åˆ†æ›´æ–°"
            }
        
        except Exception as e:
            sync_entry = {
                "timestamp": datetime.now().isoformat(),
                "node_id": self.node_id,
                "source_node": source_node,
                "key": key,
                "operation": "apply_diff",
                "diff": diff,
                "success": False,
                "error": str(e)
            }
            
            self.sync_log.append(sync_entry)
            
            return {
                "success": False,
                "error": str(e),
                "message": f"åº”ç”¨å·®åˆ†æ›´æ–°å¤±è´¥: {str(e)}"
            }
    
    def get_sync_package(self, target_node: str, keys: List[str] = None) -> Dict[str, Any]:
        """ç”ŸæˆåŒæ­¥åŒ…"""
        if keys is None:
            keys = list(self.local_data.keys())
        
        sync_package = {
            "source_node": self.node_id,
            "target_node": target_node,
            "timestamp": datetime.now().isoformat(),
            "updates": []
        }
        
        total_original_size = 0
        total_compressed_size = 0
        
        for key in keys:
            if key in self.local_data:
                data = self.local_data[key]
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å†å²æ•°æ®ç”¨äºå·®åˆ†
                last_sync = self.get_last_sync_data(target_node, key)
                
                if last_sync:
                    # ç”Ÿæˆå·®åˆ†
                    diff = self.diff_engine.compute_diff(last_sync, data)
                    update_type = "diff"
                    payload = diff
                else:
                    # å…¨é‡æ•°æ®
                    update_type = "full"
                    payload = data
                
                original_size = len(json.dumps(data))
                compressed_size = len(json.dumps(payload))
                
                total_original_size += original_size
                total_compressed_size += compressed_size
                
                sync_package["updates"].append({
                    "key": key,
                    "type": update_type,
                    "payload": payload,
                    "original_size": original_size,
                    "compressed_size": compressed_size
                })
        
        sync_package["summary"] = {
            "total_updates": len(sync_package["updates"]),
            "total_original_size": total_original_size,
            "total_compressed_size": total_compressed_size,
            "compression_ratio": total_compressed_size / total_original_size if total_original_size > 0 else 0
        }
        
        return sync_package
    
    def get_last_sync_data(self, target_node: str, key: str) -> Optional[Dict[str, Any]]:
        """è·å–ä¸Šæ¬¡åŒæ­¥çš„æ•°æ®ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œåº”è¯¥ä»æŒä¹…åŒ–å­˜å‚¨ä¸­è·å–
        # è¿™é‡Œç®€åŒ–ä¸ºè¿”å›Noneï¼Œè¡¨ç¤ºæ²¡æœ‰å†å²æ•°æ®
        return None
    
    def get_sync_statistics(self) -> Dict[str, Any]:
        """è·å–åŒæ­¥ç»Ÿè®¡ä¿¡æ¯"""
        total_syncs = len(self.sync_log)
        successful_syncs = sum(1 for entry in self.sync_log if entry.get("success", True))
        failed_syncs = total_syncs - successful_syncs
        
        # è®¡ç®—å¹³å‡å‹ç¼©æ¯”
        compression_ratios = []
        for entry in self.sync_log:
            if "data_size" in entry and "diff_size" in entry and entry["data_size"] > 0:
                compression_ratios.append(entry["diff_size"] / entry["data_size"])
        
        avg_compression_ratio = sum(compression_ratios) / len(compression_ratios) if compression_ratios else 0
        
        return {
            "node_id": self.node_id,
            "total_syncs": total_syncs,
            "successful_syncs": successful_syncs,
            "failed_syncs": failed_syncs,
            "success_rate": successful_syncs / total_syncs if total_syncs > 0 else 0,
            "average_compression_ratio": avg_compression_ratio,
            "data_keys": list(self.local_data.keys()),
            "last_sync_times": self.last_sync_time
        }

# ä½¿ç”¨ç¤ºä¾‹
def demo_data_sync():
    """æ¼”ç¤ºæ•°æ®åŒæ­¥åŠŸèƒ½"""
    # åˆ›å»ºä¸¤ä¸ªèŠ‚ç‚¹
    node_a = DataSyncManager("node_a")
    node_b = DataSyncManager("node_b")
    
    print("=== æ•°æ®åŒæ­¥æ¼”ç¤º ===")
    
    # èŠ‚ç‚¹Aæ›´æ–°æ•°æ®
    user_data = {
        "users": {
            "user_1": {"name": "Alice", "age": 25, "email": "alice@example.com"},
            "user_2": {"name": "Bob", "age": 30, "email": "bob@example.com"}
        },
        "settings": {
            "theme": "dark",
            "language": "en",
            "notifications": True
        }
    }
    
    result_a = node_a.update_local_data("app_data", user_data)
    print(f"èŠ‚ç‚¹Aæ›´æ–°æ•°æ®ï¼Œå‹ç¼©æ¯”: {result_a['compression_ratio']:.2%}")
    
    # ç”ŸæˆåŒæ­¥åŒ…
    sync_package = node_a.get_sync_package("node_b", ["app_data"])
    print(f"\nç”ŸæˆåŒæ­¥åŒ…:")
    print(f"  æ›´æ–°æ•°é‡: {sync_package['summary']['total_updates']}")
    print(f"  åŸå§‹å¤§å°: {sync_package['summary']['total_original_size']} bytes")
    print(f"  å‹ç¼©å¤§å°: {sync_package['summary']['total_compressed_size']} bytes")
    print(f"  å‹ç¼©æ¯”: {sync_package['summary']['compression_ratio']:.2%}")
    
    # èŠ‚ç‚¹Båº”ç”¨åŒæ­¥åŒ…
    for update in sync_package["updates"]:
        if update["type"] == "full":
            # å…¨é‡æ›´æ–°
            node_b.local_data[update["key"]] = update["payload"]
        else:
            # å·®åˆ†æ›´æ–°
            result_b = node_b.apply_remote_diff(
                update["key"], 
                update["payload"], 
                sync_package["source_node"]
            )
            print(f"\nèŠ‚ç‚¹Båº”ç”¨å·®åˆ†: {result_b['message']}")
    
    # èŠ‚ç‚¹Aå†æ¬¡æ›´æ–°æ•°æ®
    updated_user_data = user_data.copy()
    updated_user_data["users"]["user_3"] = {"name": "Charlie", "age": 28, "email": "charlie@example.com"}
    updated_user_data["settings"]["theme"] = "light"
    
    result_a2 = node_a.update_local_data("app_data", updated_user_data)
    print(f"\nèŠ‚ç‚¹Aå†æ¬¡æ›´æ–°æ•°æ®ï¼Œå‹ç¼©æ¯”: {result_a2['compression_ratio']:.2%}")
    
    # æŸ¥çœ‹åŒæ­¥ç»Ÿè®¡
    print("\n=== åŒæ­¥ç»Ÿè®¡ ===")
    stats_a = node_a.get_sync_statistics()
    stats_b = node_b.get_sync_statistics()
    
    print(f"èŠ‚ç‚¹A: æˆåŠŸç‡ {stats_a['success_rate']:.2%}, å¹³å‡å‹ç¼©æ¯” {stats_a['average_compression_ratio']:.2%}")
    print(f"èŠ‚ç‚¹B: æˆåŠŸç‡ {stats_b['success_rate']:.2%}, å¹³å‡å‹ç¼©æ¯” {stats_b['average_compression_ratio']:.2%}")

# è¿è¡Œæ¼”ç¤º
demo_data_sync()
```

### åº”ç”¨åœºæ™¯3ï¼šé…ç½®ç®¡ç†ç³»ç»Ÿ

**åœºæ™¯æè¿°**ï¼šç®¡ç†åº”ç”¨é…ç½®çš„å˜æ›´ï¼Œæ”¯æŒç¯å¢ƒé—´é…ç½®åŒæ­¥å’Œå›æ»šã€‚

```python
from agently_format.core.diff import DiffEngine
from typing import Dict, Any, List, Optional
from datetime import datetime
import json
import copy

class ConfigurationManager:
    """é…ç½®ç®¡ç†ç³»ç»Ÿ"""
    
    def __init__(self, environment: str):
        self.environment = environment
        self.diff_engine = DiffEngine()
        self.configurations = {}  # config_name -> config_data
        self.config_history = {}  # config_name -> [history_entries]
        self.config_templates = {}  # é…ç½®æ¨¡æ¿
    
    def register_config_template(self, name: str, template: Dict[str, Any]):
        """æ³¨å†Œé…ç½®æ¨¡æ¿"""
        self.config_templates[name] = template
    
    def create_config_from_template(self, config_name: str, template_name: str, 
                                  overrides: Dict[str, Any] = None) -> Dict[str, Any]:
        """ä»æ¨¡æ¿åˆ›å»ºé…ç½®"""
        if template_name not in self.config_templates:
            raise ValueError(f"æ¨¡æ¿ {template_name} ä¸å­˜åœ¨")
        
        # å¤åˆ¶æ¨¡æ¿
        config = copy.deepcopy(self.config_templates[template_name])
        
        # åº”ç”¨è¦†ç›–å€¼
        if overrides:
            config = self.merge_configs(config, overrides)
        
        # ä¿å­˜é…ç½®
        self.update_configuration(config_name, config, f"ä»æ¨¡æ¿ {template_name} åˆ›å»º")
        
        return config
    
    def update_configuration(self, config_name: str, new_config: Dict[str, Any], 
                           description: str = "é…ç½®æ›´æ–°") -> Dict[str, Any]:
        """æ›´æ–°é…ç½®"""
        old_config = self.configurations.get(config_name, {})
        
        # è®¡ç®—å·®åˆ†
        diff_result = self.diff_engine.compute_diff(old_config, new_config)
        
        # æ›´æ–°é…ç½®
        self.configurations[config_name] = new_config
        
        # è®°å½•å†å²
        history_entry = {
            "timestamp": datetime.now().isoformat(),
            "environment": self.environment,
            "description": description,
            "diff": diff_result,
            "config_snapshot": copy.deepcopy(new_config)
        }
        
        if config_name not in self.config_history:
            self.config_history[config_name] = []
        
        self.config_history[config_name].append(history_entry)
        
        return {
            "success": True,
            "config_name": config_name,
            "changes": diff_result,
            "change_summary": self.summarize_config_changes(diff_result)
        }
    
    def rollback_configuration(self, config_name: str, steps: int = 1) -> Dict[str, Any]:
        """å›æ»šé…ç½®"""
        if config_name not in self.config_history:
            return {"success": False, "error": "é…ç½®å†å²ä¸å­˜åœ¨"}
        
        history = self.config_history[config_name]
        
        if len(history) <= steps:
            return {"success": False, "error": "å›æ»šæ­¥æ•°è¶…è¿‡å†å²è®°å½•"}
        
        # è·å–ç›®æ ‡é…ç½®
        target_entry = history[-(steps + 1)]
        target_config = target_entry["config_snapshot"]
        
        # æ›´æ–°é…ç½®
        result = self.update_configuration(
            config_name, 
            target_config, 
            f"å›æ»š {steps} æ­¥åˆ° {target_entry['timestamp']}"
        )
        
        return result
    
    def sync_config_between_environments(self, config_name: str, 
                                       target_manager: 'ConfigurationManager',
                                       sync_mode: str = "diff") -> Dict[str, Any]:
        """åœ¨ç¯å¢ƒé—´åŒæ­¥é…ç½®"""
        if config_name not in self.configurations:
            return {"success": False, "error": "æºé…ç½®ä¸å­˜åœ¨"}
        
        source_config = self.configurations[config_name]
        target_config = target_manager.configurations.get(config_name, {})
        
        if sync_mode == "full":
            # å…¨é‡åŒæ­¥
            result = target_manager.update_configuration(
                config_name,
                source_config,
                f"ä» {self.environment} ç¯å¢ƒå…¨é‡åŒæ­¥"
            )
        else:
            # å·®åˆ†åŒæ­¥
            diff = self.diff_engine.compute_diff(target_config, source_config)
            
            if not diff.get("changes"):
                return {
                    "success": True,
                    "message": "é…ç½®å·²åŒæ­¥ï¼Œæ— éœ€æ›´æ–°",
                    "changes": []
                }
            
            # åº”ç”¨å·®åˆ†
            new_config = self.diff_engine.apply_diff(target_config, diff)
            
            result = target_manager.update_configuration(
                config_name,
                new_config,
                f"ä» {self.environment} ç¯å¢ƒå·®åˆ†åŒæ­¥"
            )
        
        return result
    
    def merge_configs(self, base_config: Dict[str, Any], 
                     override_config: Dict[str, Any]) -> Dict[str, Any]:
        """åˆå¹¶é…ç½®"""
        merged = copy.deepcopy(base_config)
        
        def deep_merge(base: Dict[str, Any], override: Dict[str, Any]):
            for key, value in override.items():
                if key in base and isinstance(base[key], dict) and isinstance(value, dict):
                    deep_merge(base[key], value)
                else:
                    base[key] = value
        
        deep_merge(merged, override_config)
        return merged
    
    def summarize_config_changes(self, diff: Dict[str, Any]) -> Dict[str, Any]:
        """æ±‡æ€»é…ç½®å˜æ›´"""
        summary = {
            "added_keys": [],
            "modified_keys": [],
            "deleted_keys": [],
            "total_changes": 0
        }
        
        for change in diff.get("changes", []):
            change_type = change.get("type")
            path = change.get("path", "")
            
            if change_type == "add":
                summary["added_keys"].append(path)
            elif change_type == "modify":
                summary["modified_keys"].append(path)
            elif change_type == "delete":
                summary["deleted_keys"].append(path)
            
            summary["total_changes"] += 1
        
        return summary
    
    def validate_config_consistency(self) -> Dict[str, Any]:
        """éªŒè¯é…ç½®ä¸€è‡´æ€§"""
        issues = []
        
        for config_name, config in self.configurations.items():
            # æ£€æŸ¥å¿…éœ€å­—æ®µ
            if "version" not in config:
                issues.append(f"é…ç½® {config_name} ç¼ºå°‘ç‰ˆæœ¬ä¿¡æ¯")
            
            # æ£€æŸ¥ç¯å¢ƒç‰¹å®šé…ç½®
            if self.environment == "production":
                if config.get("debug", False):
                    issues.append(f"ç”Ÿäº§ç¯å¢ƒé…ç½® {config_name} ä¸åº”å¯ç”¨debugæ¨¡å¼")
        
        return {
            "is_consistent": len(issues) == 0,
            "issues": issues,
            "total_configs": len(self.configurations)
        }
    
    def export_config_report(self) -> Dict[str, Any]:
        """å¯¼å‡ºé…ç½®æŠ¥å‘Š"""
        report = {
            "environment": self.environment,
            "timestamp": datetime.now().isoformat(),
            "configurations": {},
            "summary": {
                "total_configs": len(self.configurations),
                "total_history_entries": sum(len(history) for history in self.config_history.values())
            }
        }
        
        for config_name, config in self.configurations.items():
            history = self.config_history.get(config_name, [])
            
            report["configurations"][config_name] = {
                "current_config": config,
                "last_updated": history[-1]["timestamp"] if history else None,
                "total_updates": len(history),
                "recent_changes": [entry["description"] for entry in history[-3:]]  # æœ€è¿‘3æ¬¡å˜æ›´
            }
        
        return report

# ä½¿ç”¨ç¤ºä¾‹
def demo_config_management():
    """æ¼”ç¤ºé…ç½®ç®¡ç†åŠŸèƒ½"""
    # åˆ›å»ºä¸åŒç¯å¢ƒçš„é…ç½®ç®¡ç†å™¨
    dev_manager = ConfigurationManager("development")
    prod_manager = ConfigurationManager("production")
    
    print("=== é…ç½®ç®¡ç†æ¼”ç¤º ===")
    
    # æ³¨å†Œé…ç½®æ¨¡æ¿
    app_template = {
        "app_name": "MyApp",
        "version": "1.0.0",
        "server": {
            "host": "localhost",
            "port": 8000,
            "workers": 1,
            "debug": True
        },
        "database": {
            "host": "localhost",
            "port": 5432,
            "name": "myapp_dev"
        },
        "logging": {
            "level": "DEBUG",
            "file": "app.log"
        }
    }
    
    dev_manager.register_config_template("app_template", app_template)
    prod_manager.register_config_template("app_template", app_template)
    
    # å¼€å‘ç¯å¢ƒåˆ›å»ºé…ç½®
    dev_config = dev_manager.create_config_from_template("app_config", "app_template")
    print("åˆ›å»ºå¼€å‘ç¯å¢ƒé…ç½®")
    
    # ç”Ÿäº§ç¯å¢ƒåˆ›å»ºé…ç½®ï¼ˆå¸¦è¦†ç›–ï¼‰
    prod_overrides = {
        "server": {
            "host": "0.0.0.0",
            "workers": 4,
            "debug": False
        },
        "database": {
            "host": "prod-db.example.com",
            "name": "myapp_prod"
        },
        "logging": {
            "level": "INFO"
        }
    }
    
    prod_config = prod_manager.create_config_from_template(
        "app_config", "app_template", prod_overrides
    )
    print("åˆ›å»ºç”Ÿäº§ç¯å¢ƒé…ç½®")
    
    # æ›´æ–°å¼€å‘ç¯å¢ƒé…ç½®
    updated_dev_config = copy.deepcopy(dev_config)
    updated_dev_config["server"]["port"] = 8080
    updated_dev_config["features"] = {"new_feature": True}
    
    update_result = dev_manager.update_configuration(
        "app_config", updated_dev_config, "æ·»åŠ æ–°åŠŸèƒ½é…ç½®"
    )
    
    print(f"\nå¼€å‘ç¯å¢ƒé…ç½®æ›´æ–°:")
    print(f"  å˜æ›´æ•°é‡: {update_result['change_summary']['total_changes']}")
    print(f"  æ–°å¢å­—æ®µ: {update_result['change_summary']['added_keys']}")
    print(f"  ä¿®æ”¹å­—æ®µ: {update_result['change_summary']['modified_keys']}")
    
    # åŒæ­¥åˆ°ç”Ÿäº§ç¯å¢ƒ
    sync_result = dev_manager.sync_config_between_environments(
        "app_config", prod_manager, "diff"
    )
    
    print(f"\nåŒæ­¥åˆ°ç”Ÿäº§ç¯å¢ƒ: {sync_result['success']}")
    if sync_result['success']:
        print(f"  å˜æ›´æ•°é‡: {sync_result['change_summary']['total_changes']}")
    
    # éªŒè¯é…ç½®ä¸€è‡´æ€§
    dev_consistency = dev_manager.validate_config_consistency()
    prod_consistency = prod_manager.validate_config_consistency()
    
    print(f"\né…ç½®ä¸€è‡´æ€§æ£€æŸ¥:")
    print(f"  å¼€å‘ç¯å¢ƒ: {'é€šè¿‡' if dev_consistency['is_consistent'] else 'å¤±è´¥'}")
    print(f"  ç”Ÿäº§ç¯å¢ƒ: {'é€šè¿‡' if prod_consistency['is_consistent'] else 'å¤±è´¥'}")
    
    if not prod_consistency['is_consistent']:
        print(f"  ç”Ÿäº§ç¯å¢ƒé—®é¢˜: {prod_consistency['issues']}")
    
    # å›æ»šæ¼”ç¤º
    rollback_result = dev_manager.rollback_configuration("app_config", 1)
    print(f"\né…ç½®å›æ»š: {rollback_result['success']}")

# è¿è¡Œæ¼”ç¤º
demo_config_management()
```

### å¸¸è§é—®é¢˜è§£å†³æ–¹æ¡ˆ

**Q1: å¦‚ä½•å¤„ç†å¤§å‹æ•°æ®ç»“æ„çš„å·®åˆ†è®¡ç®—æ€§èƒ½é—®é¢˜ï¼Ÿ**

A1: ä½¿ç”¨åˆ†å±‚å·®åˆ†å’Œç¼“å­˜ä¼˜åŒ–ï¼š

```python
from agently_format.core.diff import DiffEngine
from typing import Dict, Any
import hashlib
import json

class OptimizedDiffEngine:
    """ä¼˜åŒ–çš„å·®åˆ†å¼•æ“"""
    
    def __init__(self):
        self.diff_engine = DiffEngine()
        self.hash_cache = {}  # å“ˆå¸Œç¼“å­˜
        self.diff_cache = {}  # å·®åˆ†ç¼“å­˜
    
    def compute_hash(self, data: Dict[str, Any]) -> str:
        """è®¡ç®—æ•°æ®å“ˆå¸Œ"""
        data_str = json.dumps(data, sort_keys=True)
        return hashlib.md5(data_str.encode()).hexdigest()
    
    def compute_optimized_diff(self, old_data: Dict[str, Any], 
                             new_data: Dict[str, Any]) -> Dict[str, Any]:
        """ä¼˜åŒ–çš„å·®åˆ†è®¡ç®—"""
        old_hash = self.compute_hash(old_data)
        new_hash = self.compute_hash(new_data)
        
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"{old_hash}:{new_hash}"
        if cache_key in self.diff_cache:
            return self.diff_cache[cache_key]
        
        # å¦‚æœå“ˆå¸Œç›¸åŒï¼Œæ— éœ€è®¡ç®—å·®åˆ†
        if old_hash == new_hash:
            result = {"changes": [], "unchanged": True}
            self.diff_cache[cache_key] = result
            return result
        
        # åˆ†å±‚å¤„ç†å¤§å‹ç»“æ„
        if len(json.dumps(old_data)) > 10000:  # å¤§äº10KB
            result = self.compute_hierarchical_diff(old_data, new_data)
        else:
            result = self.diff_engine.compute_diff(old_data, new_data)
        
        # ç¼“å­˜ç»“æœ
        self.diff_cache[cache_key] = result
        return result
    
    def compute_hierarchical_diff(self, old_data: Dict[str, Any], 
                                new_data: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†å±‚å·®åˆ†è®¡ç®—"""
        changes = []
        
        # å…ˆæ¯”è¾ƒé¡¶å±‚é”®
        old_keys = set(old_data.keys())
        new_keys = set(new_data.keys())
        
        # å¤„ç†åˆ é™¤çš„é”®
        for key in old_keys - new_keys:
            changes.append({
                "type": "delete",
                "path": key,
                "old_value": old_data[key]
            })
        
        # å¤„ç†æ–°å¢çš„é”®
        for key in new_keys - old_keys:
            changes.append({
                "type": "add",
                "path": key,
                "new_value": new_data[key]
            })
        
        # å¤„ç†ä¿®æ”¹çš„é”®
        for key in old_keys & new_keys:
            old_value = old_data[key]
            new_value = new_data[key]
            
            if isinstance(old_value, dict) and isinstance(new_value, dict):
                # é€’å½’å¤„ç†åµŒå¥—å­—å…¸
                sub_diff = self.compute_optimized_diff(old_value, new_value)
                for change in sub_diff.get("changes", []):
                    change["path"] = f"{key}.{change['path']}"
                    changes.append(change)
            elif old_value != new_value:
                changes.append({
                    "type": "modify",
                    "path": key,
                    "old_value": old_value,
                    "new_value": new_value
                })
        
        return {"changes": changes}
```

**Q2: å¦‚ä½•å¤„ç†å·®åˆ†åº”ç”¨æ—¶çš„å†²çªï¼Ÿ**

A2: å®ç°å†²çªæ£€æµ‹å’Œè§£å†³æœºåˆ¶ï¼š

```python
from agently_format.core.diff import DiffEngine
from typing import Dict, Any, List, Optional
from enum import Enum

class ConflictResolution(Enum):
    """å†²çªè§£å†³ç­–ç•¥"""
    MANUAL = "manual"  # æ‰‹åŠ¨è§£å†³
    SOURCE_WINS = "source_wins"  # æºæ•°æ®ä¼˜å…ˆ
    TARGET_WINS = "target_wins"  # ç›®æ ‡æ•°æ®ä¼˜å…ˆ
    MERGE = "merge"  # å°è¯•åˆå¹¶

class ConflictAwareDiffEngine:
    """æ”¯æŒå†²çªå¤„ç†çš„å·®åˆ†å¼•æ“"""
    
    def __init__(self):
        self.diff_engine = DiffEngine()
    
    def apply_diff_with_conflict_detection(self, 
                                         target_data: Dict[str, Any],
                                         diff: Dict[str, Any],
                                         current_data: Dict[str, Any] = None,
                                         resolution: ConflictResolution = ConflictResolution.MANUAL) -> Dict[str, Any]:
        """åº”ç”¨å·®åˆ†å¹¶æ£€æµ‹å†²çª"""
        if current_data is None:
            current_data = target_data
        
        conflicts = self.detect_conflicts(target_data, diff, current_data)
        
        if not conflicts:
            # æ— å†²çªï¼Œç›´æ¥åº”ç”¨
            result_data = self.diff_engine.apply_diff(target_data, diff)
            return {
                "success": True,
                "data": result_data,
                "conflicts": [],
                "resolution_applied": None
            }
        
        # æœ‰å†²çªï¼Œæ ¹æ®ç­–ç•¥å¤„ç†
        if resolution == ConflictResolution.MANUAL:
            return {
                "success": False,
                "data": target_data,
                "conflicts": conflicts,
                "resolution_applied": None,
                "message": "æ£€æµ‹åˆ°å†²çªï¼Œéœ€è¦æ‰‹åŠ¨è§£å†³"
            }
        
        # è‡ªåŠ¨è§£å†³å†²çª
        resolved_diff = self.resolve_conflicts(diff, conflicts, resolution)
        result_data = self.diff_engine.apply_diff(target_data, resolved_diff)
        
        return {
            "success": True,
            "data": result_data,
            "conflicts": conflicts,
            "resolution_applied": resolution.value,
            "message": f"ä½¿ç”¨ {resolution.value} ç­–ç•¥è§£å†³äº† {len(conflicts)} ä¸ªå†²çª"
        }
    
    def detect_conflicts(self, target_data: Dict[str, Any], 
                        diff: Dict[str, Any], 
                        current_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æ£€æµ‹å†²çª"""
        conflicts = []
        
        for change in diff.get("changes", []):
            path = change.get("path", "")
            change_type = change.get("type")
            
            # è·å–å½“å‰è·¯å¾„çš„å€¼
            current_value = self.get_value_by_path(current_data, path)
            target_value = self.get_value_by_path(target_data, path)
            
            # æ£€æµ‹å†²çª
            if change_type == "modify":
                expected_old_value = change.get("old_value")
                if current_value != expected_old_value:
                    conflicts.append({
                        "path": path,
                        "type": "modify_conflict",
                        "expected_old_value": expected_old_value,
                        "actual_current_value": current_value,
                        "new_value": change.get("new_value"),
                        "message": f"è·¯å¾„ {path} çš„å½“å‰å€¼ä¸æœŸæœ›çš„æ—§å€¼ä¸åŒ¹é…"
                    })
            
            elif change_type == "delete":
                if current_value is None:
                    conflicts.append({
                        "path": path,
                        "type": "delete_conflict",
                        "message": f"è·¯å¾„ {path} å·²ç»ä¸å­˜åœ¨ï¼Œæ— æ³•åˆ é™¤"
                    })
            
            elif change_type == "add":
                if current_value is not None:
                    conflicts.append({
                        "path": path,
                        "type": "add_conflict",
                        "existing_value": current_value,
                        "new_value": change.get("new_value"),
                        "message": f"è·¯å¾„ {path} å·²å­˜åœ¨å€¼ï¼Œæ— æ³•æ·»åŠ "
                    })
        
        return conflicts
    
    def resolve_conflicts(self, diff: Dict[str, Any], 
                         conflicts: List[Dict[str, Any]], 
                         resolution: ConflictResolution) -> Dict[str, Any]:
        """è§£å†³å†²çª"""
        resolved_diff = diff.copy()
        conflict_paths = {conflict["path"] for conflict in conflicts}
        
        if resolution == ConflictResolution.SOURCE_WINS:
            # æºæ•°æ®ä¼˜å…ˆï¼Œä¿æŒåŸå·®åˆ†ä¸å˜
            pass
        
        elif resolution == ConflictResolution.TARGET_WINS:
            # ç›®æ ‡æ•°æ®ä¼˜å…ˆï¼Œç§»é™¤å†²çªçš„å˜æ›´
            resolved_diff["changes"] = [
                change for change in diff.get("changes", [])
                if change.get("path") not in conflict_paths
            ]
        
        elif resolution == ConflictResolution.MERGE:
            # å°è¯•åˆå¹¶ï¼Œè¿™é‡Œç®€åŒ–ä¸ºæºæ•°æ®ä¼˜å…ˆ
            # å®é™…åº”ç”¨ä¸­å¯ä»¥å®ç°æ›´å¤æ‚çš„åˆå¹¶é€»è¾‘
            pass
        
        return resolved_diff
    
    def get_value_by_path(self, data: Dict[str, Any], path: str) -> Any:
        """æ ¹æ®è·¯å¾„è·å–å€¼"""
        if not path:
            return data
        
        keys = path.split(".")
        current = data
        
        try:
            for key in keys:
                if isinstance(current, dict) and key in current:
                    current = current[key]
                else:
                    return None
            return current
        except (KeyError, TypeError):
            return None
```

---

## 6. å¤šæ¨¡å‹é€‚é…å™¨æœ€ä½³å®è·µ

### æ ¸å¿ƒåŠŸèƒ½æ¦‚è¿°

å¤šæ¨¡å‹é€‚é…å™¨æä¾›ç»Ÿä¸€çš„æ¥å£æ¥å¤„ç†ä¸åŒAIæ¨¡å‹çš„è¾“å…¥è¾“å‡ºæ ¼å¼ï¼Œæ”¯æŒæ¨¡å‹åˆ‡æ¢ã€å‚æ•°é€‚é…ã€å“åº”æ ¼å¼åŒ–ç­‰åŠŸèƒ½ã€‚

### åº”ç”¨åœºæ™¯1ï¼šAIæ¨¡å‹ç»Ÿä¸€ç®¡ç†

**åœºæ™¯æè¿°**ï¼šåœ¨åº”ç”¨ä¸­é›†æˆå¤šä¸ªAIæ¨¡å‹ï¼Œæä¾›ç»Ÿä¸€çš„è°ƒç”¨æ¥å£ã€‚

```python
from agently_format.core.adapters import ModelAdapter
from typing import Dict, Any, List, Optional, Union
from abc import ABC, abstractmethod
import json
import time
from datetime import datetime

class BaseModelProvider(ABC):
    """æ¨¡å‹æä¾›è€…åŸºç±»"""
    
    @abstractmethod
    def generate_response(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """ç”Ÿæˆå“åº”"""
        pass
    
    @abstractmethod
    def get_model_info(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        pass

class OpenAIProvider(BaseModelProvider):
    """OpenAIæ¨¡å‹æä¾›è€…"""
    
    def __init__(self, api_key: str, model_name: str = "gpt-3.5-turbo"):
        self.api_key = api_key
        self.model_name = model_name
    
    def generate_response(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """ç”Ÿæˆå“åº”ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        # æ¨¡æ‹ŸAPIè°ƒç”¨
        time.sleep(0.1)  # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
        
        return {
            "model": self.model_name,
            "response": f"OpenAIå“åº”: {prompt[:50]}...",
            "usage": {
                "prompt_tokens": len(prompt.split()),
                "completion_tokens": 20,
                "total_tokens": len(prompt.split()) + 20
            },
            "finish_reason": "stop"
        }
    
    def get_model_info(self) -> Dict[str, Any]:
        return {
            "provider": "OpenAI",
            "model": self.model_name,
            "max_tokens": 4096,
            "supports_streaming": True
        }

class AnthropicProvider(BaseModelProvider):
    """Anthropicæ¨¡å‹æä¾›è€…"""
    
    def __init__(self, api_key: str, model_name: str = "claude-3-sonnet"):
        self.api_key = api_key
        self.model_name = model_name
    
    def generate_response(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """ç”Ÿæˆå“åº”ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        time.sleep(0.15)  # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
        
        return {
            "model": self.model_name,
            "content": f"Claudeå“åº”: {prompt[:50]}...",
            "stop_reason": "end_turn",
            "usage": {
                "input_tokens": len(prompt.split()),
                "output_tokens": 25
            }
        }
    
    def get_model_info(self) -> Dict[str, Any]:
        return {
            "provider": "Anthropic",
            "model": self.model_name,
            "max_tokens": 8192,
            "supports_streaming": True
        }

class UnifiedModelManager:
    """ç»Ÿä¸€æ¨¡å‹ç®¡ç†å™¨"""
    
    def __init__(self):
        self.providers = {}  # provider_name -> provider_instance
        self.adapters = {}   # provider_name -> adapter_instance
        self.default_provider = None
        self.usage_stats = {}  # ä½¿ç”¨ç»Ÿè®¡
    
    def register_provider(self, name: str, provider: BaseModelProvider, 
                         adapter: ModelAdapter = None):
        """æ³¨å†Œæ¨¡å‹æä¾›è€…"""
        self.providers[name] = provider
        
        if adapter:
            self.adapters[name] = adapter
        else:
            # ä½¿ç”¨é»˜è®¤é€‚é…å™¨
            self.adapters[name] = self.create_default_adapter(name, provider)
        
        if self.default_provider is None:
            self.default_provider = name
        
        # åˆå§‹åŒ–ä½¿ç”¨ç»Ÿè®¡
        self.usage_stats[name] = {
            "total_requests": 0,
            "total_tokens": 0,
            "total_cost": 0.0,
            "average_response_time": 0.0,
            "error_count": 0
        }
    
    def create_default_adapter(self, provider_name: str, 
                             provider: BaseModelProvider) -> ModelAdapter:
        """åˆ›å»ºé»˜è®¤é€‚é…å™¨"""
        return ModelAdapter(
            input_formatter=self.get_input_formatter(provider_name),
            output_formatter=self.get_output_formatter(provider_name),
            error_handler=self.get_error_handler(provider_name)
        )
    
    def get_input_formatter(self, provider_name: str):
        """è·å–è¾“å…¥æ ¼å¼åŒ–å™¨"""
        def format_input(prompt: str, **kwargs) -> Dict[str, Any]:
            if provider_name == "openai":
                return {
                    "messages": [{"role": "user", "content": prompt}],
                    "model": kwargs.get("model", "gpt-3.5-turbo"),
                    "max_tokens": kwargs.get("max_tokens", 1000),
                    "temperature": kwargs.get("temperature", 0.7)
                }
            elif provider_name == "anthropic":
                return {
                    "prompt": f"Human: {prompt}\n\nAssistant:",
                    "model": kwargs.get("model", "claude-3-sonnet"),
                    "max_tokens_to_sample": kwargs.get("max_tokens", 1000),
                    "temperature": kwargs.get("temperature", 0.7)
                }
            else:
                return {"prompt": prompt, **kwargs}
        
        return format_input
    
    def get_output_formatter(self, provider_name: str):
        """è·å–è¾“å‡ºæ ¼å¼åŒ–å™¨"""
        def format_output(response: Dict[str, Any]) -> Dict[str, Any]:
            if provider_name == "openai":
                return {
                    "text": response.get("response", ""),
                    "model": response.get("model"),
                    "usage": response.get("usage", {}),
                    "finish_reason": response.get("finish_reason")
                }
            elif provider_name == "anthropic":
                return {
                    "text": response.get("content", ""),
                    "model": response.get("model"),
                    "usage": {
                        "prompt_tokens": response.get("usage", {}).get("input_tokens", 0),
                        "completion_tokens": response.get("usage", {}).get("output_tokens", 0),
                        "total_tokens": response.get("usage", {}).get("input_tokens", 0) + 
                                       response.get("usage", {}).get("output_tokens", 0)
                    },
                    "finish_reason": response.get("stop_reason")
                }
            else:
                return response
        
        return format_output
    
    def get_error_handler(self, provider_name: str):
        """è·å–é”™è¯¯å¤„ç†å™¨"""
        def handle_error(error: Exception) -> Dict[str, Any]:
            return {
                "error": True,
                "provider": provider_name,
                "error_type": type(error).__name__,
                "error_message": str(error),
                "timestamp": datetime.now().isoformat()
            }
        
        return handle_error
    
    def generate_response(self, prompt: str, provider: str = None, 
                         **kwargs) -> Dict[str, Any]:
        """ç”Ÿæˆå“åº”"""
        if provider is None:
            provider = self.default_provider
        
        if provider not in self.providers:
            return {
                "error": True,
                "message": f"æœªçŸ¥çš„æä¾›è€…: {provider}",
                "available_providers": list(self.providers.keys())
            }
        
        start_time = time.time()
        
        try:
            # è·å–æä¾›è€…å’Œé€‚é…å™¨
            provider_instance = self.providers[provider]
            adapter = self.adapters[provider]
            
            # æ ¼å¼åŒ–è¾“å…¥
            formatted_input = adapter.input_formatter(prompt, **kwargs)
            
            # è°ƒç”¨æ¨¡å‹
            raw_response = provider_instance.generate_response(prompt, **formatted_input)
            
            # æ ¼å¼åŒ–è¾“å‡º
            formatted_response = adapter.output_formatter(raw_response)
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            response_time = time.time() - start_time
            self.update_usage_stats(provider, formatted_response, response_time)
            
            # æ·»åŠ å…ƒæ•°æ®
            formatted_response.update({
                "provider": provider,
                "response_time": response_time,
                "timestamp": datetime.now().isoformat()
            })
            
            return formatted_response
        
        except Exception as e:
            # é”™è¯¯å¤„ç†
            adapter = self.adapters[provider]
            error_response = adapter.error_handler(e)
            
            # æ›´æ–°é”™è¯¯ç»Ÿè®¡
            self.usage_stats[provider]["error_count"] += 1
            
            return error_response
    
    def update_usage_stats(self, provider: str, response: Dict[str, Any], 
                          response_time: float):
        """æ›´æ–°ä½¿ç”¨ç»Ÿè®¡"""
        stats = self.usage_stats[provider]
        
        stats["total_requests"] += 1
        
        usage = response.get("usage", {})
        total_tokens = usage.get("total_tokens", 0)
        stats["total_tokens"] += total_tokens
        
        # è®¡ç®—å¹³å‡å“åº”æ—¶é—´
        current_avg = stats["average_response_time"]
        total_requests = stats["total_requests"]
        stats["average_response_time"] = (
            (current_avg * (total_requests - 1) + response_time) / total_requests
        )
        
        # ä¼°ç®—æˆæœ¬ï¼ˆç®€åŒ–è®¡ç®—ï¼‰
        cost_per_token = self.get_cost_per_token(provider)
        stats["total_cost"] += total_tokens * cost_per_token
    
    def get_cost_per_token(self, provider: str) -> float:
        """è·å–æ¯tokenæˆæœ¬ï¼ˆç®€åŒ–ï¼‰"""
        cost_map = {
            "openai": 0.0001,
            "anthropic": 0.00015,
            "default": 0.0001
        }
        return cost_map.get(provider, cost_map["default"])
    
    def get_usage_report(self) -> Dict[str, Any]:
        """è·å–ä½¿ç”¨æŠ¥å‘Š"""
        total_requests = sum(stats["total_requests"] for stats in self.usage_stats.values())
        total_cost = sum(stats["total_cost"] for stats in self.usage_stats.values())
        
        return {
            "summary": {
                "total_requests": total_requests,
                "total_cost": total_cost,
                "active_providers": len(self.providers)
            },
            "by_provider": self.usage_stats,
            "recommendations": self.generate_recommendations()
        }
    
    def generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        # åˆ†ææˆæœ¬æ•ˆç‡
        cost_efficiency = {}
        for provider, stats in self.usage_stats.items():
            if stats["total_requests"] > 0:
                cost_per_request = stats["total_cost"] / stats["total_requests"]
                cost_efficiency[provider] = cost_per_request
        
        if cost_efficiency:
            cheapest = min(cost_efficiency, key=cost_efficiency.get)
            most_expensive = max(cost_efficiency, key=cost_efficiency.get)
            
            if cost_efficiency[most_expensive] > cost_efficiency[cheapest] * 1.5:
                recommendations.append(
                    f"è€ƒè™‘æ›´å¤šä½¿ç”¨ {cheapest} æä¾›è€…ï¼Œæˆæœ¬æ•ˆç‡æ›´é«˜"
                )
        
        # åˆ†æå“åº”æ—¶é—´
        response_times = {
            provider: stats["average_response_time"]
            for provider, stats in self.usage_stats.items()
            if stats["total_requests"] > 0
        }
        
        if response_times:
            fastest = min(response_times, key=response_times.get)
            recommendations.append(
                f"{fastest} æä¾›è€…å“åº”æ—¶é—´æœ€å¿«ï¼Œé€‚åˆå®æ—¶åº”ç”¨"
            )
        
        return recommendations

# ä½¿ç”¨ç¤ºä¾‹
def demo_unified_model_management():
    """æ¼”ç¤ºç»Ÿä¸€æ¨¡å‹ç®¡ç†"""
    # åˆ›å»ºæ¨¡å‹ç®¡ç†å™¨
    manager = UnifiedModelManager()
    
    # æ³¨å†Œæä¾›è€…
    openai_provider = OpenAIProvider("fake-api-key")
    anthropic_provider = AnthropicProvider("fake-api-key")
    
    manager.register_provider("openai", openai_provider)
    manager.register_provider("anthropic", anthropic_provider)
    
    print("=== ç»Ÿä¸€æ¨¡å‹ç®¡ç†æ¼”ç¤º ===")
    
    # æµ‹è¯•ä¸åŒæä¾›è€…
    test_prompt = "è¯·è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ "
    
    # ä½¿ç”¨OpenAI
    response1 = manager.generate_response(test_prompt, provider="openai")
    print(f"OpenAIå“åº”: {response1.get('text', 'N/A')[:50]}...")
    print(f"å“åº”æ—¶é—´: {response1.get('response_time', 0):.3f}s")
    
    # ä½¿ç”¨Anthropic
    response2 = manager.generate_response(test_prompt, provider="anthropic")
    print(f"\nAnthropicå“åº”: {response2.get('text', 'N/A')[:50]}...")
    print(f"å“åº”æ—¶é—´: {response2.get('response_time', 0):.3f}s")
    
    # ä½¿ç”¨é»˜è®¤æä¾›è€…
    response3 = manager.generate_response("å¦ä¸€ä¸ªæµ‹è¯•é—®é¢˜")
    print(f"\né»˜è®¤æä¾›è€…å“åº”: {response3.get('text', 'N/A')[:50]}...")
    
    # æŸ¥çœ‹ä½¿ç”¨æŠ¥å‘Š
    print("\n=== ä½¿ç”¨æŠ¥å‘Š ===")
    report = manager.get_usage_report()
    print(f"æ€»è¯·æ±‚æ•°: {report['summary']['total_requests']}")
    print(f"æ€»æˆæœ¬: ${report['summary']['total_cost']:.4f}")
    
    print("\nå„æä¾›è€…ç»Ÿè®¡:")
    for provider, stats in report["by_provider"].items():
        if stats["total_requests"] > 0:
            print(f"  {provider}: {stats['total_requests']}æ¬¡è¯·æ±‚, "
                  f"å¹³å‡å“åº”æ—¶é—´ {stats['average_response_time']:.3f}s")
    
    if report["recommendations"]:
        print("\nä¼˜åŒ–å»ºè®®:")
        for rec in report["recommendations"]:
            print(f"  - {rec}")

# è¿è¡Œæ¼”ç¤º
demo_unified_model_management()
```

### åº”ç”¨åœºæ™¯2ï¼šæ™ºèƒ½è·¯ç”±å’Œè´Ÿè½½å‡è¡¡

**åœºæ™¯æè¿°**ï¼šæ ¹æ®è¯·æ±‚ç±»å‹ã€æ¨¡å‹æ€§èƒ½å’Œæˆæœ¬è‡ªåŠ¨é€‰æ‹©æœ€é€‚åˆçš„æ¨¡å‹ã€‚

```python
from agently_format.core.adapters import ModelAdapter
from typing import Dict, Any, List, Optional
from enum import Enum
import random
import time

class RequestType(Enum):
    """è¯·æ±‚ç±»å‹"""
    SIMPLE_QA = "simple_qa"  # ç®€å•é—®ç­”
    COMPLEX_REASONING = "complex_reasoning"  # å¤æ‚æ¨ç†
    CODE_GENERATION = "code_generation"  # ä»£ç ç”Ÿæˆ
    CREATIVE_WRITING = "creative_writing"  # åˆ›æ„å†™ä½œ
    DATA_ANALYSIS = "data_analysis"  # æ•°æ®åˆ†æ

class RoutingStrategy(Enum):
    """è·¯ç”±ç­–ç•¥"""
    COST_OPTIMIZED = "cost_optimized"  # æˆæœ¬ä¼˜åŒ–
    PERFORMANCE_OPTIMIZED = "performance_optimized"  # æ€§èƒ½ä¼˜åŒ–
    BALANCED = "balanced"  # å¹³è¡¡ç­–ç•¥
    ROUND_ROBIN = "round_robin"  # è½®è¯¢

class IntelligentModelRouter:
    """æ™ºèƒ½æ¨¡å‹è·¯ç”±å™¨"""
    
    def __init__(self, model_manager):
        self.model_manager = model_manager
        self.model_capabilities = {}  # æ¨¡å‹èƒ½åŠ›è¯„åˆ†
        self.model_costs = {}  # æ¨¡å‹æˆæœ¬
        self.model_performance = {}  # æ¨¡å‹æ€§èƒ½æŒ‡æ ‡
        self.request_history = []  # è¯·æ±‚å†å²
        self.round_robin_index = 0  # è½®è¯¢ç´¢å¼•
        
        # åˆå§‹åŒ–æ¨¡å‹é…ç½®
        self.initialize_model_configs()
    
    def initialize_model_configs(self):
        """åˆå§‹åŒ–æ¨¡å‹é…ç½®"""
        # æ¨¡å‹èƒ½åŠ›è¯„åˆ†ï¼ˆ1-10åˆ†ï¼‰
        self.model_capabilities = {
            "openai": {
                RequestType.SIMPLE_QA: 8,
                RequestType.COMPLEX_REASONING: 9,
                RequestType.CODE_GENERATION: 9,
                RequestType.CREATIVE_WRITING: 8,
                RequestType.DATA_ANALYSIS: 8
            },
            "anthropic": {
                RequestType.SIMPLE_QA: 9,
                RequestType.COMPLEX_REASONING: 10,
                RequestType.CODE_GENERATION: 8,
                RequestType.CREATIVE_WRITING: 9,
                RequestType.DATA_ANALYSIS: 9
            }
        }
        
        # æ¨¡å‹æˆæœ¬ï¼ˆæ¯1000 tokensï¼‰
        self.model_costs = {
            "openai": 0.002,
            "anthropic": 0.003
        }
        
        # æ¨¡å‹æ€§èƒ½æŒ‡æ ‡
        self.model_performance = {
            "openai": {
                "average_response_time": 1.2,
                "reliability_score": 0.95,
                "throughput": 100  # requests per minute
            },
            "anthropic": {
                "average_response_time": 1.5,
                "reliability_score": 0.98,
                "throughput": 80
            }
        }
    
    def classify_request(self, prompt: str) -> RequestType:
        """åˆ†ç±»è¯·æ±‚ç±»å‹"""
        prompt_lower = prompt.lower()
        
        # ç®€å•çš„å…³é”®è¯åŒ¹é…åˆ†ç±»
        if any(keyword in prompt_lower for keyword in ["ä»£ç ", "ç¼–ç¨‹", "å‡½æ•°", "class", "def"]):
            return RequestType.CODE_GENERATION
        elif any(keyword in prompt_lower for keyword in ["åˆ†æ", "æ•°æ®", "ç»Ÿè®¡", "å›¾è¡¨"]):
            return RequestType.DATA_ANALYSIS
        elif any(keyword in prompt_lower for keyword in ["æ•…äº‹", "åˆ›ä½œ", "è¯—æ­Œ", "å°è¯´"]):
            return RequestType.CREATIVE_WRITING
        elif len(prompt.split()) > 50:  # é•¿æ–‡æœ¬é€šå¸¸éœ€è¦å¤æ‚æ¨ç†
            return RequestType.COMPLEX_REASONING
        else:
            return RequestType.SIMPLE_QA
    
    def select_model(self, request_type: RequestType, 
                    strategy: RoutingStrategy = RoutingStrategy.BALANCED) -> str:
        """é€‰æ‹©æœ€é€‚åˆçš„æ¨¡å‹"""
        available_providers = list(self.model_manager.providers.keys())
        
        if not available_providers:
            raise ValueError("æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹æä¾›è€…")
        
        if strategy == RoutingStrategy.ROUND_ROBIN:
            # è½®è¯¢ç­–ç•¥
            selected = available_providers[self.round_robin_index % len(available_providers)]
            self.round_robin_index += 1
            return selected
        
        # è®¡ç®—æ¯ä¸ªæ¨¡å‹çš„å¾—åˆ†
        model_scores = {}
        
        for provider in available_providers:
            capability_score = self.model_capabilities.get(provider, {}).get(request_type, 5)
            cost_score = 10 - (self.model_costs.get(provider, 0.002) * 1000)  # æˆæœ¬è¶Šä½åˆ†æ•°è¶Šé«˜
            performance_score = (
                (10 - self.model_performance.get(provider, {}).get("average_response_time", 2)) +
                (self.model_performance.get(provider, {}).get("reliability_score", 0.9) * 10)
            ) / 2
            
            if strategy == RoutingStrategy.COST_OPTIMIZED:
                total_score = cost_score * 0.6 + capability_score * 0.3 + performance_score * 0.1
            elif strategy == RoutingStrategy.PERFORMANCE_OPTIMIZED:
                total_score = performance_score * 0.6 + capability_score * 0.3 + cost_score * 0.1
            else:  # BALANCED
                total_score = capability_score * 0.4 + cost_score * 0.3 + performance_score * 0.3
            
            model_scores[provider] = total_score
        
        # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„æ¨¡å‹
        return max(model_scores, key=model_scores.get)
    
    def route_request(self, prompt: str, 
                     strategy: RoutingStrategy = RoutingStrategy.BALANCED,
                     **kwargs) -> Dict[str, Any]:
        """è·¯ç”±è¯·æ±‚åˆ°æœ€é€‚åˆçš„æ¨¡å‹"""
        # åˆ†ç±»è¯·æ±‚
        request_type = self.classify_request(prompt)
        
        # é€‰æ‹©æ¨¡å‹
        selected_provider = self.select_model(request_type, strategy)
        
        # è®°å½•è·¯ç”±å†³ç­–
        routing_info = {
            "request_type": request_type.value,
            "selected_provider": selected_provider,
            "strategy": strategy.value,
            "timestamp": time.time()
        }
        
        # ç”Ÿæˆå“åº”
        response = self.model_manager.generate_response(
            prompt, provider=selected_provider, **kwargs
        )
        
        # æ·»åŠ è·¯ç”±ä¿¡æ¯
        response["routing_info"] = routing_info
        
        # è®°å½•å†å²
        self.request_history.append({
            "prompt": prompt[:100],  # åªä¿å­˜å‰100ä¸ªå­—ç¬¦
            "routing_info": routing_info,
            "response_time": response.get("response_time", 0),
            "success": not response.get("error", False)
        })
        
        return response
    
    def get_routing_analytics(self) -> Dict[str, Any]:
        """è·å–è·¯ç”±åˆ†ææŠ¥å‘Š"""
        if not self.request_history:
            return {"message": "æš‚æ— è·¯ç”±å†å²æ•°æ®"}
        
        # ç»Ÿè®¡å„ç§æŒ‡æ ‡
        total_requests = len(self.request_history)
        success_requests = sum(1 for req in self.request_history if req["success"])
        
        # æŒ‰æä¾›è€…ç»Ÿè®¡
        provider_stats = {}
        request_type_stats = {}
        
        for req in self.request_history:
            provider = req["routing_info"]["selected_provider"]
            req_type = req["routing_info"]["request_type"]
            
            if provider not in provider_stats:
                provider_stats[provider] = {"count": 0, "total_time": 0, "success_count": 0}
            
            provider_stats[provider]["count"] += 1
            provider_stats[provider]["total_time"] += req["response_time"]
            if req["success"]:
                provider_stats[provider]["success_count"] += 1
            
            if req_type not in request_type_stats:
                request_type_stats[req_type] = 0
            request_type_stats[req_type] += 1
        
        # è®¡ç®—å¹³å‡å“åº”æ—¶é—´
        for provider in provider_stats:
            stats = provider_stats[provider]
            stats["average_response_time"] = stats["total_time"] / stats["count"]
            stats["success_rate"] = stats["success_count"] / stats["count"]
        
        return {
            "summary": {
                "total_requests": total_requests,
                "success_rate": success_requests / total_requests,
                "average_response_time": sum(req["response_time"] for req in self.request_history) / total_requests
            },
            "provider_distribution": provider_stats,
            "request_type_distribution": request_type_stats,
            "recommendations": self.generate_routing_recommendations(provider_stats)
        }
    
    def generate_routing_recommendations(self, provider_stats: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆè·¯ç”±ä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        if not provider_stats:
            return recommendations
        
        # æ‰¾å‡ºæ€§èƒ½æœ€å¥½çš„æä¾›è€…
        best_provider = min(provider_stats.keys(), 
                           key=lambda p: provider_stats[p]["average_response_time"])
        
        # æ‰¾å‡ºæˆåŠŸç‡æœ€é«˜çš„æä¾›è€…
        most_reliable = max(provider_stats.keys(), 
                           key=lambda p: provider_stats[p]["success_rate"])
        
        recommendations.append(f"{best_provider} æä¾›è€…å“åº”æ—¶é—´æœ€å¿«")
        recommendations.append(f"{most_reliable} æä¾›è€…æˆåŠŸç‡æœ€é«˜")
        
        # æ£€æŸ¥è´Ÿè½½åˆ†å¸ƒ
        total_requests = sum(stats["count"] for stats in provider_stats.values())
        for provider, stats in provider_stats.items():
            usage_percentage = (stats["count"] / total_requests) * 100
            if usage_percentage > 80:
                recommendations.append(f"{provider} æä¾›è€…è´Ÿè½½è¿‡é«˜ ({usage_percentage:.1f}%)ï¼Œå»ºè®®åˆ†æ•£è´Ÿè½½")
        
        return recommendations

# ä½¿ç”¨ç¤ºä¾‹
def demo_intelligent_routing():
    """æ¼”ç¤ºæ™ºèƒ½è·¯ç”±"""
    from agently_format.core.adapters import ModelAdapter
    
    # åˆ›å»ºæ¨¡å‹ç®¡ç†å™¨ï¼ˆä½¿ç”¨ä¹‹å‰çš„ä»£ç ï¼‰
    manager = UnifiedModelManager()
    
    # æ³¨å†Œæä¾›è€…
    openai_provider = OpenAIProvider("fake-api-key")
    anthropic_provider = AnthropicProvider("fake-api-key")
    
    manager.register_provider("openai", openai_provider)
    manager.register_provider("anthropic", anthropic_provider)
    
    # åˆ›å»ºæ™ºèƒ½è·¯ç”±å™¨
    router = IntelligentModelRouter(manager)
    
    print("=== æ™ºèƒ½è·¯ç”±æ¼”ç¤º ===")
    
    # æµ‹è¯•ä¸åŒç±»å‹çš„è¯·æ±‚
    test_requests = [
        "è¯·å†™ä¸€ä¸ªPythonå‡½æ•°æ¥è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—",
        "åˆ†æä¸€ä¸‹è¿™ç»„é”€å”®æ•°æ®çš„è¶‹åŠ¿",
        "å†™ä¸€ä¸ªå…³äºæœªæ¥åŸå¸‚çš„ç§‘å¹»æ•…äº‹",
        "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
        "è¯·è¯¦ç»†è§£é‡Šé‡å­è®¡ç®—çš„åŸç†å’Œåº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬å…¶åœ¨å¯†ç å­¦ã€ä¼˜åŒ–é—®é¢˜å’Œæ¨¡æ‹Ÿç­‰é¢†åŸŸçš„æ½œåœ¨å½±å“"
    ]
    
    strategies = [RoutingStrategy.BALANCED, RoutingStrategy.COST_OPTIMIZED, RoutingStrategy.PERFORMANCE_OPTIMIZED]
    
    for i, prompt in enumerate(test_requests):
        strategy = strategies[i % len(strategies)]
        
        print(f"\nè¯·æ±‚ {i+1}: {prompt[:50]}...")
        
        response = router.route_request(prompt, strategy=strategy)
        
        routing_info = response.get("routing_info", {})
        print(f"è¯·æ±‚ç±»å‹: {routing_info.get('request_type')}")
        print(f"é€‰æ‹©çš„æä¾›è€…: {routing_info.get('selected_provider')}")
        print(f"è·¯ç”±ç­–ç•¥: {routing_info.get('strategy')}")
        print(f"å“åº”æ—¶é—´: {response.get('response_time', 0):.3f}s")
    
    # æŸ¥çœ‹è·¯ç”±åˆ†æ
    print("\n=== è·¯ç”±åˆ†ææŠ¥å‘Š ===")
    analytics = router.get_routing_analytics()
    
    summary = analytics["summary"]
    print(f"æ€»è¯·æ±‚æ•°: {summary['total_requests']}")
    print(f"æˆåŠŸç‡: {summary['success_rate']:.2%}")
    print(f"å¹³å‡å“åº”æ—¶é—´: {summary['average_response_time']:.3f}s")
    
    print("\næä¾›è€…åˆ†å¸ƒ:")
    for provider, stats in analytics["provider_distribution"].items():
        print(f"  {provider}: {stats['count']}æ¬¡è¯·æ±‚, "
              f"å¹³å‡å“åº”æ—¶é—´ {stats['average_response_time']:.3f}s, "
              f"æˆåŠŸç‡ {stats['success_rate']:.2%}")
    
    print("\nè¯·æ±‚ç±»å‹åˆ†å¸ƒ:")
    for req_type, count in analytics["request_type_distribution"].items():
        print(f"  {req_type}: {count}æ¬¡")
    
    if analytics["recommendations"]:
        print("\nä¼˜åŒ–å»ºè®®:")
        for rec in analytics["recommendations"]:
            print(f"  - {rec}")

# è¿è¡Œæ¼”ç¤º
demo_intelligent_routing()
```

### åº”ç”¨åœºæ™¯3ï¼šæ¨¡å‹æ€§èƒ½ç›‘æ§å’Œè‡ªåŠ¨åˆ‡æ¢

**åœºæ™¯æè¿°**ï¼šç›‘æ§æ¨¡å‹æ€§èƒ½ï¼Œåœ¨æ£€æµ‹åˆ°å¼‚å¸¸æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°å¤‡ç”¨æ¨¡å‹ã€‚

```python
from agently_format.core.adapters import ModelAdapter
from typing import Dict, Any, List, Optional, Callable
from dataclasses import dataclass
from datetime import datetime, timedelta
import time
import statistics
from collections import deque

@dataclass
class HealthMetrics:
    """å¥åº·æŒ‡æ ‡"""
    response_time: float
    success_rate: float
    error_count: int
    total_requests: int
    last_error: Optional[str] = None
    timestamp: datetime = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now()

class ModelHealthMonitor:
    """æ¨¡å‹å¥åº·ç›‘æ§å™¨"""
    
    def __init__(self, model_manager, check_interval: int = 60):
        self.model_manager = model_manager
        self.check_interval = check_interval  # æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
        self.health_history = {}  # provider -> deque of HealthMetrics
        self.alert_thresholds = {
            "max_response_time": 5.0,  # æœ€å¤§å“åº”æ—¶é—´ï¼ˆç§’ï¼‰
            "min_success_rate": 0.8,   # æœ€å°æˆåŠŸç‡
            "max_error_rate": 0.2      # æœ€å¤§é”™è¯¯ç‡
        }
        self.failover_enabled = True
        self.primary_provider = None
        self.backup_providers = []
        self.current_provider = None
        self.alert_callbacks = []  # å‘Šè­¦å›è°ƒå‡½æ•°
        
        # åˆå§‹åŒ–å¥åº·å†å²
        for provider in model_manager.providers.keys():
            self.health_history[provider] = deque(maxlen=100)  # ä¿ç•™æœ€è¿‘100æ¡è®°å½•
    
    def set_failover_config(self, primary: str, backups: List[str]):
        """è®¾ç½®æ•…éšœè½¬ç§»é…ç½®"""
        self.primary_provider = primary
        self.backup_providers = backups
        self.current_provider = primary
    
    def add_alert_callback(self, callback: Callable[[str, Dict[str, Any]], None]):
        """æ·»åŠ å‘Šè­¦å›è°ƒ"""
        self.alert_callbacks.append(callback)
    
    def record_request(self, provider: str, response_time: float, 
                      success: bool, error_message: str = None):
        """è®°å½•è¯·æ±‚ç»“æœ"""
        if provider not in self.health_history:
            self.health_history[provider] = deque(maxlen=100)
        
        # è®¡ç®—æœ€è¿‘çš„æŒ‡æ ‡
        recent_records = list(self.health_history[provider])[-20:]  # æœ€è¿‘20æ¡è®°å½•
        
        if recent_records:
            recent_success_count = sum(1 for r in recent_records if r.success_rate > 0)
            recent_total = len(recent_records)
            success_rate = recent_success_count / recent_total
            error_count = recent_total - recent_success_count
        else:
            success_rate = 1.0 if success else 0.0
            error_count = 0 if success else 1
        
        # åˆ›å»ºå¥åº·æŒ‡æ ‡
        metrics = HealthMetrics(
            response_time=response_time,
            success_rate=success_rate,
            error_count=error_count,
            total_requests=len(recent_records) + 1,
            last_error=error_message if not success else None
        )
        
        self.health_history[provider].append(metrics)
        
        # æ£€æŸ¥å¥åº·çŠ¶æ€
        self.check_health(provider, metrics)
    
    def check_health(self, provider: str, metrics: HealthMetrics):
        """æ£€æŸ¥æä¾›è€…å¥åº·çŠ¶æ€"""
        alerts = []
        
        # æ£€æŸ¥å“åº”æ—¶é—´
        if metrics.response_time > self.alert_thresholds["max_response_time"]:
            alerts.append({
                "type": "high_response_time",
                "message": f"{provider} å“åº”æ—¶é—´è¿‡é«˜: {metrics.response_time:.2f}s",
                "severity": "warning"
            })
        
        # æ£€æŸ¥æˆåŠŸç‡
        if metrics.success_rate < self.alert_thresholds["min_success_rate"]:
            alerts.append({
                "type": "low_success_rate",
                "message": f"{provider} æˆåŠŸç‡è¿‡ä½: {metrics.success_rate:.2%}",
                "severity": "critical"
            })
        
        # æ£€æŸ¥é”™è¯¯ç‡
        error_rate = metrics.error_count / metrics.total_requests
        if error_rate > self.alert_thresholds["max_error_rate"]:
            alerts.append({
                "type": "high_error_rate",
                "message": f"{provider} é”™è¯¯ç‡è¿‡é«˜: {error_rate:.2%}",
                "severity": "critical"
            })
        
        # è§¦å‘å‘Šè­¦å’Œæ•…éšœè½¬ç§»
        for alert in alerts:
            self.trigger_alert(provider, alert)
            
            # å¦‚æœæ˜¯ä¸¥é‡å‘Šè­¦ä¸”å¯ç”¨äº†æ•…éšœè½¬ç§»
            if (alert["severity"] == "critical" and 
                self.failover_enabled and 
                provider == self.current_provider):
                self.trigger_failover(provider, alert["message"])
    
    def trigger_alert(self, provider: str, alert: Dict[str, Any]):
        """è§¦å‘å‘Šè­¦"""
        alert_data = {
            "provider": provider,
            "timestamp": datetime.now().isoformat(),
            **alert
        }
        
        # è°ƒç”¨å‘Šè­¦å›è°ƒ
        for callback in self.alert_callbacks:
            try:
                callback(provider, alert_data)
            except Exception as e:
                print(f"å‘Šè­¦å›è°ƒæ‰§è¡Œå¤±è´¥: {e}")
    
    def trigger_failover(self, failed_provider: str, reason: str):
        """è§¦å‘æ•…éšœè½¬ç§»"""
        if not self.backup_providers:
            print(f"æ— å¯ç”¨çš„å¤‡ç”¨æä¾›è€…ï¼Œæ— æ³•ä» {failed_provider} æ•…éšœè½¬ç§»")
            return
        
        # é€‰æ‹©æœ€å¥åº·çš„å¤‡ç”¨æä¾›è€…
        best_backup = self.select_best_backup()
        
        if best_backup:
            old_provider = self.current_provider
            self.current_provider = best_backup
            
            failover_alert = {
                "type": "failover",
                "message": f"ä» {old_provider} æ•…éšœè½¬ç§»åˆ° {best_backup}: {reason}",
                "severity": "info",
                "old_provider": old_provider,
                "new_provider": best_backup
            }
            
            self.trigger_alert("system", failover_alert)
            print(f"æ•…éšœè½¬ç§»: {old_provider} -> {best_backup}")
    
    def select_best_backup(self) -> Optional[str]:
        """é€‰æ‹©æœ€ä½³å¤‡ç”¨æä¾›è€…"""
        backup_scores = {}
        
        for provider in self.backup_providers:
            if provider not in self.health_history or not self.health_history[provider]:
                backup_scores[provider] = 0.5  # é»˜è®¤åˆ†æ•°
                continue
            
            recent_metrics = list(self.health_history[provider])[-10:]  # æœ€è¿‘10æ¡è®°å½•
            
            if recent_metrics:
                avg_response_time = statistics.mean(m.response_time for m in recent_metrics)
                avg_success_rate = statistics.mean(m.success_rate for m in recent_metrics)
                
                # è®¡ç®—å¥åº·åˆ†æ•°ï¼ˆå“åº”æ—¶é—´è¶Šä½è¶Šå¥½ï¼ŒæˆåŠŸç‡è¶Šé«˜è¶Šå¥½ï¼‰
                time_score = max(0, 1 - (avg_response_time / 10))  # 10ç§’ä¸ºæœ€å·®
                success_score = avg_success_rate
                
                backup_scores[provider] = (time_score + success_score) / 2
            else:
                backup_scores[provider] = 0.5
        
        if backup_scores:
            return max(backup_scores, key=backup_scores.get)
        return None
    
    def get_current_provider(self) -> str:
        """è·å–å½“å‰æ´»è·ƒçš„æä¾›è€…"""
        return self.current_provider or self.primary_provider
    
    def get_health_report(self) -> Dict[str, Any]:
        """è·å–å¥åº·æŠ¥å‘Š"""
        report = {
            "current_provider": self.current_provider,
            "primary_provider": self.primary_provider,
            "backup_providers": self.backup_providers,
            "provider_health": {},
            "system_status": "healthy"
        }
        
        for provider, history in self.health_history.items():
            if not history:
                continue
            
            recent_metrics = list(history)[-10:]  # æœ€è¿‘10æ¡è®°å½•
            
            if recent_metrics:
                avg_response_time = statistics.mean(m.response_time for m in recent_metrics)
                avg_success_rate = statistics.mean(m.success_rate for m in recent_metrics)
                total_requests = sum(m.total_requests for m in recent_metrics)
                
                # åˆ¤æ–­å¥åº·çŠ¶æ€
                is_healthy = (
                    avg_response_time <= self.alert_thresholds["max_response_time"] and
                    avg_success_rate >= self.alert_thresholds["min_success_rate"]
                )
                
                report["provider_health"][provider] = {
                    "status": "healthy" if is_healthy else "unhealthy",
                    "average_response_time": avg_response_time,
                    "average_success_rate": avg_success_rate,
                    "total_requests": total_requests,
                    "last_check": recent_metrics[-1].timestamp.isoformat()
                }
                
                if not is_healthy and provider == self.current_provider:
                    report["system_status"] = "degraded"
        
        return report

class MonitoredModelManager(UnifiedModelManager):
    """å¸¦ç›‘æ§çš„æ¨¡å‹ç®¡ç†å™¨"""
    
    def __init__(self):
        super().__init__()
        self.monitor = ModelHealthMonitor(self)
        
        # è®¾ç½®é»˜è®¤å‘Šè­¦å›è°ƒ
        self.monitor.add_alert_callback(self.default_alert_handler)
    
    def setup_failover(self, primary: str, backups: List[str]):
        """è®¾ç½®æ•…éšœè½¬ç§»"""
        self.monitor.set_failover_config(primary, backups)
    
    def default_alert_handler(self, provider: str, alert_data: Dict[str, Any]):
        """é»˜è®¤å‘Šè­¦å¤„ç†å™¨"""
        timestamp = alert_data.get("timestamp", "")
        message = alert_data.get("message", "")
        severity = alert_data.get("severity", "info")
        
        print(f"[{timestamp}] {severity.upper()}: {message}")
    
    def generate_response(self, prompt: str, provider: str = None, **kwargs) -> Dict[str, Any]:
        """ç”Ÿæˆå“åº”ï¼ˆå¸¦ç›‘æ§ï¼‰"""
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæä¾›è€…ï¼Œä½¿ç”¨ç›‘æ§å™¨æ¨èçš„æä¾›è€…
        if provider is None:
            provider = self.monitor.get_current_provider() or self.default_provider
        
        start_time = time.time()
        
        try:
            response = super().generate_response(prompt, provider, **kwargs)
            
            # è®°å½•æˆåŠŸè¯·æ±‚
            response_time = time.time() - start_time
            self.monitor.record_request(provider, response_time, True)
            
            return response
        
        except Exception as e:
            # è®°å½•å¤±è´¥è¯·æ±‚
            response_time = time.time() - start_time
            self.monitor.record_request(provider, response_time, False, str(e))
            
            # å¦‚æœå¯ç”¨äº†æ•…éšœè½¬ç§»ï¼Œå°è¯•ä½¿ç”¨å¤‡ç”¨æä¾›è€…
            if (self.monitor.failover_enabled and 
                provider == self.monitor.current_provider and 
                self.monitor.backup_providers):
                
                backup_provider = self.monitor.select_best_backup()
                if backup_provider:
                    print(f"å°è¯•ä½¿ç”¨å¤‡ç”¨æä¾›è€…: {backup_provider}")
                    return self.generate_response(prompt, backup_provider, **kwargs)
            
            raise e
    
    def get_system_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        health_report = self.monitor.get_health_report()
        usage_report = self.get_usage_report()
        
        return {
            "health": health_report,
            "usage": usage_report,
            "timestamp": datetime.now().isoformat()
        }

# ä½¿ç”¨ç¤ºä¾‹
def demo_health_monitoring():
    """æ¼”ç¤ºå¥åº·ç›‘æ§"""
    # åˆ›å»ºå¸¦ç›‘æ§çš„æ¨¡å‹ç®¡ç†å™¨
    manager = MonitoredModelManager()
    
    # æ³¨å†Œæä¾›è€…
    openai_provider = OpenAIProvider("fake-api-key")
    anthropic_provider = AnthropicProvider("fake-api-key")
    
    manager.register_provider("openai", openai_provider)
    manager.register_provider("anthropic", anthropic_provider)
    
    # è®¾ç½®æ•…éšœè½¬ç§»
    manager.setup_failover("openai", ["anthropic"])
    
    print("=== å¥åº·ç›‘æ§æ¼”ç¤º ===")
    
    # æ¨¡æ‹Ÿæ­£å¸¸è¯·æ±‚
    for i in range(5):
        try:
            response = manager.generate_response(f"æµ‹è¯•è¯·æ±‚ {i+1}")
            print(f"è¯·æ±‚ {i+1} æˆåŠŸ: {response.get('provider')}")
        except Exception as e:
            print(f"è¯·æ±‚ {i+1} å¤±è´¥: {e}")
        
        time.sleep(0.1)  # çŸ­æš‚å»¶è¿Ÿ
    
    # æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€
    print("\n=== ç³»ç»ŸçŠ¶æ€æŠ¥å‘Š ===")
    status = manager.get_system_status()
    
    health = status["health"]
    print(f"å½“å‰æä¾›è€…: {health['current_provider']}")
    print(f"ç³»ç»ŸçŠ¶æ€: {health['system_status']}")
    
    print("\næä¾›è€…å¥åº·çŠ¶æ€:")
    for provider, health_info in health["provider_health"].items():
        print(f"  {provider}: {health_info['status']} - "
              f"å“åº”æ—¶é—´ {health_info['average_response_time']:.3f}s, "
              f"æˆåŠŸç‡ {health_info['average_success_rate']:.2%}")

# è¿è¡Œæ¼”ç¤º
demo_health_monitoring()
```

### å¸¸è§é—®é¢˜è§£å†³æ–¹æ¡ˆ

**Q1: å¦‚ä½•å¤„ç†ä¸åŒæ¨¡å‹çš„APIé™åˆ¶å’Œé…é¢ç®¡ç†ï¼Ÿ**

A1: å®ç°é…é¢ç®¡ç†å’Œé™æµæœºåˆ¶ï¼š

```python
from agently_format.core.adapters import ModelAdapter
from typing import Dict, Any, Optional
from datetime import datetime, timedelta
from collections import defaultdict
import time
import threading

class QuotaManager:
    """é…é¢ç®¡ç†å™¨"""
    
    def __init__(self):
        self.provider_quotas = {}  # provider -> quota config
        self.usage_tracking = defaultdict(lambda: defaultdict(int))  # provider -> {period -> usage}
        self.rate_limits = {}  # provider -> rate limit config
        self.last_request_time = {}  # provider -> last request timestamp
        self.lock = threading.Lock()
    
    def set_quota(self, provider: str, daily_limit: int, monthly_limit: int):
        """è®¾ç½®é…é¢é™åˆ¶"""
        self.provider_quotas[provider] = {
            "daily_limit": daily_limit,
            "monthly_limit": monthly_limit
        }
    
    def set_rate_limit(self, provider: str, requests_per_minute: int):
        """è®¾ç½®é€Ÿç‡é™åˆ¶"""
        self.rate_limits[provider] = {
            "requests_per_minute": requests_per_minute,
            "min_interval": 60.0 / requests_per_minute  # æœ€å°è¯·æ±‚é—´éš”
        }
    
    def check_quota(self, provider: str, tokens_to_use: int = 1) -> Dict[str, Any]:
        """æ£€æŸ¥é…é¢æ˜¯å¦å¯ç”¨"""
        with self.lock:
            now = datetime.now()
            today = now.strftime("%Y-%m-%d")
            this_month = now.strftime("%Y-%m")
            
            # æ£€æŸ¥æ—¥é…é¢
            daily_usage = self.usage_tracking[provider][f"daily_{today}"]
            daily_limit = self.provider_quotas.get(provider, {}).get("daily_limit", float('inf'))
            
            if daily_usage + tokens_to_use > daily_limit:
                return {
                    "allowed": False,
                    "reason": "daily_quota_exceeded",
                    "daily_usage": daily_usage,
                    "daily_limit": daily_limit
                }
            
            # æ£€æŸ¥æœˆé…é¢
            monthly_usage = self.usage_tracking[provider][f"monthly_{this_month}"]
            monthly_limit = self.provider_quotas.get(provider, {}).get("monthly_limit", float('inf'))
            
            if monthly_usage + tokens_to_use > monthly_limit:
                return {
                    "allowed": False,
                    "reason": "monthly_quota_exceeded",
                    "monthly_usage": monthly_usage,
                    "monthly_limit": monthly_limit
                }
            
            return {
                "allowed": True,
                "daily_remaining": daily_limit - daily_usage,
                "monthly_remaining": monthly_limit - monthly_usage
            }
    
    def check_rate_limit(self, provider: str) -> Dict[str, Any]:
        """æ£€æŸ¥é€Ÿç‡é™åˆ¶"""
        if provider not in self.rate_limits:
            return {"allowed": True, "wait_time": 0}
        
        with self.lock:
            now = time.time()
            last_request = self.last_request_time.get(provider, 0)
            min_interval = self.rate_limits[provider]["min_interval"]
            
            time_since_last = now - last_request
            
            if time_since_last < min_interval:
                wait_time = min_interval - time_since_last
                return {
                    "allowed": False,
                    "wait_time": wait_time,
                    "reason": "rate_limit_exceeded"
                }
            
            return {"allowed": True, "wait_time": 0}
    
    def record_usage(self, provider: str, tokens_used: int):
        """è®°å½•ä½¿ç”¨é‡"""
        with self.lock:
            now = datetime.now()
            today = now.strftime("%Y-%m-%d")
            this_month = now.strftime("%Y-%m")
            
            self.usage_tracking[provider][f"daily_{today}"] += tokens_used
            self.usage_tracking[provider][f"monthly_{this_month}"] += tokens_used
            self.last_request_time[provider] = time.time()
    
    def get_usage_summary(self) -> Dict[str, Any]:
        """è·å–ä½¿ç”¨é‡æ‘˜è¦"""
        summary = {}
        now = datetime.now()
        today = now.strftime("%Y-%m-%d")
        this_month = now.strftime("%Y-%m")
        
        for provider in self.provider_quotas:
            daily_usage = self.usage_tracking[provider].get(f"daily_{today}", 0)
            monthly_usage = self.usage_tracking[provider].get(f"monthly_{this_month}", 0)
            
            quotas = self.provider_quotas[provider]
            
            summary[provider] = {
                "daily": {
                    "used": daily_usage,
                    "limit": quotas["daily_limit"],
                    "remaining": quotas["daily_limit"] - daily_usage,
                    "usage_percentage": (daily_usage / quotas["daily_limit"]) * 100
                },
                "monthly": {
                    "used": monthly_usage,
                    "limit": quotas["monthly_limit"],
                    "remaining": quotas["monthly_limit"] - monthly_usage,
                    "usage_percentage": (monthly_usage / quotas["monthly_limit"]) * 100
                }
            }
        
        return summary

class QuotaAwareModelManager(UnifiedModelManager):
    """æ”¯æŒé…é¢ç®¡ç†çš„æ¨¡å‹ç®¡ç†å™¨"""
    
    def __init__(self):
        super().__init__()
        self.quota_manager = QuotaManager()
        
        # è®¾ç½®é»˜è®¤é…é¢ï¼ˆç¤ºä¾‹ï¼‰
        self.setup_default_quotas()
    
    def setup_default_quotas(self):
        """è®¾ç½®é»˜è®¤é…é¢"""
        # OpenAIé…é¢è®¾ç½®
        self.quota_manager.set_quota("openai", daily_limit=10000, monthly_limit=100000)
        self.quota_manager.set_rate_limit("openai", requests_per_minute=60)
        
        # Anthropicé…é¢è®¾ç½®
        self.quota_manager.set_quota("anthropic", daily_limit=8000, monthly_limit=80000)
        self.quota_manager.set_rate_limit("anthropic", requests_per_minute=50)
    
    def generate_response(self, prompt: str, provider: str = None, **kwargs) -> Dict[str, Any]:
        """ç”Ÿæˆå“åº”ï¼ˆå¸¦é…é¢ç®¡ç†ï¼‰"""
        if provider is None:
            provider = self.default_provider
        
        # ä¼°ç®—tokenä½¿ç”¨é‡ï¼ˆç®€åŒ–è®¡ç®—ï¼‰
        estimated_tokens = len(prompt.split()) + kwargs.get("max_tokens", 100)
        
        # æ£€æŸ¥é…é¢
        quota_check = self.quota_manager.check_quota(provider, estimated_tokens)
        if not quota_check["allowed"]:
            # å°è¯•ä½¿ç”¨å…¶ä»–æä¾›è€…
            alternative_provider = self.find_alternative_provider(provider)
            if alternative_provider:
                print(f"é…é¢ä¸è¶³ï¼Œåˆ‡æ¢åˆ° {alternative_provider}")
                return self.generate_response(prompt, alternative_provider, **kwargs)
            else:
                return {
                    "error": True,
                    "message": f"é…é¢ä¸è¶³: {quota_check['reason']}",
                    "quota_info": quota_check
                }
        
        # æ£€æŸ¥é€Ÿç‡é™åˆ¶
        rate_check = self.quota_manager.check_rate_limit(provider)
        if not rate_check["allowed"]:
            wait_time = rate_check["wait_time"]
            print(f"é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time:.2f} ç§’")
            time.sleep(wait_time)
        
        try:
            # è°ƒç”¨çˆ¶ç±»æ–¹æ³•ç”Ÿæˆå“åº”
            response = super().generate_response(prompt, provider, **kwargs)
            
            # è®°å½•å®é™…ä½¿ç”¨é‡
            actual_tokens = response.get("usage", {}).get("total_tokens", estimated_tokens)
            self.quota_manager.record_usage(provider, actual_tokens)
            
            # æ·»åŠ é…é¢ä¿¡æ¯
            response["quota_info"] = self.quota_manager.get_usage_summary().get(provider, {})
            
            return response
        
        except Exception as e:
            # å³ä½¿å¤±è´¥ä¹Ÿè¦è®°å½•ä½¿ç”¨é‡ï¼ˆé¿å…é…é¢æ³„éœ²ï¼‰
            self.quota_manager.record_usage(provider, estimated_tokens // 2)
            raise e
    
    def find_alternative_provider(self, current_provider: str) -> Optional[str]:
        """å¯»æ‰¾æ›¿ä»£æä¾›è€…"""
        for provider in self.providers.keys():
            if provider != current_provider:
                # æ£€æŸ¥æ›¿ä»£æä¾›è€…çš„é…é¢
                quota_check = self.quota_manager.check_quota(provider, 100)  # æ£€æŸ¥å°é‡é…é¢
                if quota_check["allowed"]:
                    return provider
        return None
    
    def get_quota_report(self) -> Dict[str, Any]:
        """è·å–é…é¢æŠ¥å‘Š"""
        return {
            "usage_summary": self.quota_manager.get_usage_summary(),
            "timestamp": datetime.now().isoformat(),
            "recommendations": self.generate_quota_recommendations()
        }
    
    def generate_quota_recommendations(self) -> List[str]:
        """ç”Ÿæˆé…é¢ä¼˜åŒ–å»ºè®®"""
        recommendations = []
        usage_summary = self.quota_manager.get_usage_summary()
        
        for provider, usage in usage_summary.items():
            daily_usage_pct = usage["daily"]["usage_percentage"]
            monthly_usage_pct = usage["monthly"]["usage_percentage"]
            
            if daily_usage_pct > 80:
                recommendations.append(f"{provider} æ—¥é…é¢ä½¿ç”¨ç‡è¿‡é«˜ ({daily_usage_pct:.1f}%)")
            
            if monthly_usage_pct > 90:
                recommendations.append(f"{provider} æœˆé…é¢å³å°†è€—å°½ ({monthly_usage_pct:.1f}%)")
            
            if daily_usage_pct < 20 and monthly_usage_pct < 20:
                recommendations.append(f"{provider} é…é¢åˆ©ç”¨ç‡è¾ƒä½ï¼Œå¯ä»¥è€ƒè™‘è°ƒæ•´")
        
        return recommendations

# ä½¿ç”¨ç¤ºä¾‹
def demo_quota_management():
    """æ¼”ç¤ºé…é¢ç®¡ç†"""
    # åˆ›å»ºæ”¯æŒé…é¢ç®¡ç†çš„æ¨¡å‹ç®¡ç†å™¨
    manager = QuotaAwareModelManager()
    
    # æ³¨å†Œæä¾›è€…
    openai_provider = OpenAIProvider("fake-api-key")
    anthropic_provider = AnthropicProvider("fake-api-key")
    
    manager.register_provider("openai", openai_provider)
    manager.register_provider("anthropic", anthropic_provider)
    
    print("=== é…é¢ç®¡ç†æ¼”ç¤º ===")
    
    # æ¨¡æ‹Ÿå¤šæ¬¡è¯·æ±‚
    for i in range(3):
        try:
            response = manager.generate_response(
                f"æµ‹è¯•è¯·æ±‚ {i+1}: è¯·è§£é‡Šäººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹",
                provider="openai"
            )
            
            print(f"\nè¯·æ±‚ {i+1} æˆåŠŸ")
            print(f"ä½¿ç”¨çš„æä¾›è€…: {response.get('provider')}")
            
            # æ˜¾ç¤ºé…é¢ä¿¡æ¯
            quota_info = response.get("quota_info", {})
            if quota_info:
                daily_info = quota_info.get("daily", {})
                print(f"æ—¥é…é¢ä½¿ç”¨: {daily_info.get('used', 0)}/{daily_info.get('limit', 0)} "
                      f"({daily_info.get('usage_percentage', 0):.1f}%)")
        
        except Exception as e:
            print(f"è¯·æ±‚ {i+1} å¤±è´¥: {e}")
    
    # æŸ¥çœ‹é…é¢æŠ¥å‘Š
    print("\n=== é…é¢ä½¿ç”¨æŠ¥å‘Š ===")
    quota_report = manager.get_quota_report()
    
    for provider, usage in quota_report["usage_summary"].items():
        print(f"\n{provider} æä¾›è€…:")
        print(f"  æ—¥ä½¿ç”¨é‡: {usage['daily']['used']}/{usage['daily']['limit']} "
              f"({usage['daily']['usage_percentage']:.1f}%)")
        print(f"  æœˆä½¿ç”¨é‡: {usage['monthly']['used']}/{usage['monthly']['limit']} "
              f"({usage['monthly']['usage_percentage']:.1f}%)")
    
    if quota_report["recommendations"]:
        print("\nä¼˜åŒ–å»ºè®®:")
        for rec in quota_report["recommendations"]:
            print(f"  - {rec}")

# è¿è¡Œæ¼”ç¤º
demo_quota_management()
```

**Q2: å¦‚ä½•å®ç°æ¨¡å‹å“åº”çš„ç¼“å­˜å’Œä¼˜åŒ–ï¼Ÿ**

A2: å®ç°æ™ºèƒ½ç¼“å­˜æœºåˆ¶ï¼š

```python
from agently_format.core.adapters import ModelAdapter
from typing import Dict, Any, Optional, Tuple
import hashlib
import json
import time
from datetime import datetime, timedelta
from collections import OrderedDict
import threading

class ResponseCache:
    """å“åº”ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, max_size: int = 1000, ttl_seconds: int = 3600):
        self.max_size = max_size
        self.ttl_seconds = ttl_seconds
        self.cache = OrderedDict()  # LRUç¼“å­˜
        self.access_times = {}  # è®¿é—®æ—¶é—´è®°å½•
        self.hit_count = 0
        self.miss_count = 0
        self.lock = threading.Lock()
    
    def generate_cache_key(self, prompt: str, provider: str, **kwargs) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        # åˆ›å»ºåŒ…å«æ‰€æœ‰ç›¸å…³å‚æ•°çš„å­—å…¸
        cache_data = {
            "prompt": prompt.strip().lower(),  # æ ‡å‡†åŒ–æç¤º
            "provider": provider,
            "params": {k: v for k, v in sorted(kwargs.items()) if k in [
                "temperature", "max_tokens", "top_p", "frequency_penalty", "presence_penalty"
            ]}
        }
        
        # ç”Ÿæˆå“ˆå¸Œ
        cache_str = json.dumps(cache_data, sort_keys=True)
        return hashlib.md5(cache_str.encode()).hexdigest()
    
    def get(self, cache_key: str) -> Optional[Dict[str, Any]]:
        """è·å–ç¼“å­˜çš„å“åº”"""
        with self.lock:
            if cache_key not in self.cache:
                self.miss_count += 1
                return None
            
            # æ£€æŸ¥TTL
            cached_time = self.access_times.get(cache_key, 0)
            if time.time() - cached_time > self.ttl_seconds:
                # ç¼“å­˜è¿‡æœŸï¼Œåˆ é™¤
                del self.cache[cache_key]
                del self.access_times[cache_key]
                self.miss_count += 1
                return None
            
            # ç¼“å­˜å‘½ä¸­ï¼Œç§»åˆ°æœ€åï¼ˆLRUï¼‰
            response = self.cache[cache_key]
            self.cache.move_to_end(cache_key)
            self.access_times[cache_key] = time.time()
            self.hit_count += 1
            
            # æ·»åŠ ç¼“å­˜æ ‡è®°
            response_copy = response.copy()
            response_copy["from_cache"] = True
            response_copy["cache_hit_time"] = datetime.now().isoformat()
            
            return response_copy
    
    def put(self, cache_key: str, response: Dict[str, Any]):
        """å­˜å‚¨å“åº”åˆ°ç¼“å­˜"""
        with self.lock:
            # å¦‚æœç¼“å­˜å·²æ»¡ï¼Œåˆ é™¤æœ€æ—§çš„æ¡ç›®
            if len(self.cache) >= self.max_size:
                oldest_key = next(iter(self.cache))
                del self.cache[oldest_key]
                del self.access_times[oldest_key]
            
            # å­˜å‚¨å“åº”ï¼ˆç§»é™¤ä¸€äº›ä¸éœ€è¦ç¼“å­˜çš„å­—æ®µï¼‰
            cacheable_response = {k: v for k, v in response.items() 
                                if k not in ["response_time", "timestamp", "from_cache"]}
            
            self.cache[cache_key] = cacheable_response
            self.access_times[cache_key] = time.time()
    
    def invalidate_pattern(self, pattern: str):
        """æ ¹æ®æ¨¡å¼å¤±æ•ˆç¼“å­˜"""
        with self.lock:
            keys_to_remove = []
            for key in self.cache.keys():
                if pattern in key:
                    keys_to_remove.append(key)
            
            for key in keys_to_remove:
                del self.cache[key]
                del self.access_times[key]
    
    def clear(self):
        """æ¸…ç©ºç¼“å­˜"""
        with self.lock:
            self.cache.clear()
            self.access_times.clear()
            self.hit_count = 0
            self.miss_count = 0
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        total_requests = self.hit_count + self.miss_count
        hit_rate = (self.hit_count / total_requests * 100) if total_requests > 0 else 0
        
        return {
            "cache_size": len(self.cache),
            "max_size": self.max_size,
            "hit_count": self.hit_count,
            "miss_count": self.miss_count,
            "hit_rate": hit_rate,
            "ttl_seconds": self.ttl_seconds
        }

class CachedModelManager(UnifiedModelManager):
    """æ”¯æŒç¼“å­˜çš„æ¨¡å‹ç®¡ç†å™¨"""
    
    def __init__(self, cache_size: int = 1000, cache_ttl: int = 3600):
        super().__init__()
        self.cache = ResponseCache(cache_size, cache_ttl)
        self.cache_enabled = True
        self.cache_bypass_keywords = ["random", "current time", "latest", "now"]  # ä¸ç¼“å­˜çš„å…³é”®è¯
    
    def should_cache(self, prompt: str, **kwargs) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ç¼“å­˜"""
        if not self.cache_enabled:
            return False
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸åº”ç¼“å­˜çš„å…³é”®è¯
        prompt_lower = prompt.lower()
        for keyword in self.cache_bypass_keywords:
            if keyword in prompt_lower:
                return False
        
        # æ£€æŸ¥å‚æ•°ä¸­æ˜¯å¦æœ‰éšæœºæ€§è®¾ç½®
        temperature = kwargs.get("temperature", 0.7)
        if temperature > 0.8:  # é«˜æ¸©åº¦è®¾ç½®é€šå¸¸æœŸæœ›éšæœºæ€§
            return False
        
        return True
    
    def generate_response(self, prompt: str, provider: str = None, **kwargs) -> Dict[str, Any]:
        """ç”Ÿæˆå“åº”ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        if provider is None:
            provider = self.default_provider
        
        # æ£€æŸ¥æ˜¯å¦åº”è¯¥ä½¿ç”¨ç¼“å­˜
        if self.should_cache(prompt, **kwargs):
            cache_key = self.cache.generate_cache_key(prompt, provider, **kwargs)
            
            # å°è¯•ä»ç¼“å­˜è·å–
            cached_response = self.cache.get(cache_key)
            if cached_response:
                print(f"ç¼“å­˜å‘½ä¸­: {cache_key[:8]}...")
                return cached_response
        
        # ç¼“å­˜æœªå‘½ä¸­æˆ–ä¸ä½¿ç”¨ç¼“å­˜ï¼Œè°ƒç”¨å®é™…API
        response = super().generate_response(prompt, provider, **kwargs)
        
        # å¦‚æœåº”è¯¥ç¼“å­˜ä¸”è¯·æ±‚æˆåŠŸï¼Œå­˜å‚¨åˆ°ç¼“å­˜
        if (self.should_cache(prompt, **kwargs) and 
            not response.get("error", False)):
            self.cache.put(cache_key, response)
        
        return response
    
    def invalidate_cache(self, pattern: str = None):
        """å¤±æ•ˆç¼“å­˜"""
        if pattern:
            self.cache.invalidate_pattern(pattern)
        else:
            self.cache.clear()
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        return self.cache.get_stats()
    
    def configure_cache(self, enabled: bool = True, 
                       bypass_keywords: List[str] = None):
        """é…ç½®ç¼“å­˜è®¾ç½®"""
        self.cache_enabled = enabled
        if bypass_keywords is not None:
            self.cache_bypass_keywords = bypass_keywords

# ä½¿ç”¨ç¤ºä¾‹
def demo_response_caching():
    """æ¼”ç¤ºå“åº”ç¼“å­˜"""
    # åˆ›å»ºæ”¯æŒç¼“å­˜çš„æ¨¡å‹ç®¡ç†å™¨
    manager = CachedModelManager(cache_size=100, cache_ttl=300)  # 5åˆ†é’ŸTTL
    
    # æ³¨å†Œæä¾›è€…
    openai_provider = OpenAIProvider("fake-api-key")
    manager.register_provider("openai", openai_provider)
    
    print("=== å“åº”ç¼“å­˜æ¼”ç¤º ===")
    
    # æµ‹è¯•ç›¸åŒè¯·æ±‚çš„ç¼“å­˜æ•ˆæœ
    test_prompt = "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿè¯·ç®€è¦è§£é‡Šã€‚"
    
    print("ç¬¬ä¸€æ¬¡è¯·æ±‚ï¼ˆåº”è¯¥è°ƒç”¨APIï¼‰:")
    start_time = time.time()
    response1 = manager.generate_response(test_prompt, temperature=0.3)
    time1 = time.time() - start_time
    print(f"å“åº”æ—¶é—´: {time1:.3f}s")
    print(f"æ¥è‡ªç¼“å­˜: {response1.get('from_cache', False)}")
    
    print("\nç¬¬äºŒæ¬¡ç›¸åŒè¯·æ±‚ï¼ˆåº”è¯¥æ¥è‡ªç¼“å­˜ï¼‰:")
    start_time = time.time()
    response2 = manager.generate_response(test_prompt, temperature=0.3)
    time2 = time.time() - start_time
    print(f"å“åº”æ—¶é—´: {time2:.3f}s")
    print(f"æ¥è‡ªç¼“å­˜: {response2.get('from_cache', False)}")
    
    print("\nä¸åŒå‚æ•°çš„è¯·æ±‚ï¼ˆåº”è¯¥è°ƒç”¨APIï¼‰:")
    start_time = time.time()
    response3 = manager.generate_response(test_prompt, temperature=0.8)
    time3 = time.time() - start_time
    print(f"å“åº”æ—¶é—´: {time3:.3f}s")
    print(f"æ¥è‡ªç¼“å­˜: {response3.get('from_cache', False)}")
    
    print("\nåŒ…å«éšæœºæ€§å…³é”®è¯çš„è¯·æ±‚ï¼ˆä¸åº”ç¼“å­˜ï¼‰:")
    random_prompt = "ç»™æˆ‘ä¸€ä¸ªéšæœºçš„ç¼–ç¨‹å»ºè®®"
    response4 = manager.generate_response(random_prompt)
    print(f"æ¥è‡ªç¼“å­˜: {response4.get('from_cache', False)}")
    
    # æŸ¥çœ‹ç¼“å­˜ç»Ÿè®¡
    print("\n=== ç¼“å­˜ç»Ÿè®¡ ===")
    stats = manager.get_cache_stats()
    print(f"ç¼“å­˜å¤§å°: {stats['cache_size']}/{stats['max_size']}")
    print(f"å‘½ä¸­æ¬¡æ•°: {stats['hit_count']}")
    print(f"æœªå‘½ä¸­æ¬¡æ•°: {stats['miss_count']}")
    print(f"å‘½ä¸­ç‡: {stats['hit_rate']:.1f}%")
    
    # æ¼”ç¤ºç¼“å­˜å¤±æ•ˆ
    print("\næ¸…ç©ºç¼“å­˜...")
    manager.invalidate_cache()
    
    print("æ¸…ç©ºåçš„ç¼“å­˜ç»Ÿè®¡:")
    stats_after = manager.get_cache_stats()
    print(f"ç¼“å­˜å¤§å°: {stats_after['cache_size']}/{stats_after['max_size']}")

# è¿è¡Œæ¼”ç¤º
demo_response_caching()
```

---

## æ€»ç»“

æœ¬æœ€ä½³å®è·µæŒ‡å—è¯¦ç»†ä»‹ç»äº†AgentlyFormaté¡¹ç›®å…­ä¸ªæ ¸å¿ƒåŠŸèƒ½æ¨¡å—çš„å®é™…åº”ç”¨åœºæ™¯å’Œè§£å†³æ–¹æ¡ˆï¼š

### ğŸ¯ æ ¸å¿ƒä»·å€¼

1. **æ™ºèƒ½JSONè¡¥å…¨**ï¼šè§£å†³AIæ¨¡å‹è¾“å‡ºä¸å®Œæ•´JSONçš„é—®é¢˜ï¼Œæä¾›æ™ºèƒ½ä¿®å¤å’ŒéªŒè¯
2. **æµå¼JSONè§£æ**ï¼šæ”¯æŒå®æ—¶å¤„ç†å¤§å‹JSONæ•°æ®æµï¼Œæå‡ç”¨æˆ·ä½“éªŒ
3. **æ•°æ®è·¯å¾„æ„å»º**ï¼šæä¾›çµæ´»çš„æ•°æ®è®¿é—®å’Œæ“ä½œæ–¹å¼ï¼Œæ”¯æŒå¤šç§è·¯å¾„æ ¼å¼
4. **SchemaéªŒè¯**ï¼šç¡®ä¿æ•°æ®è´¨é‡å’Œä¸€è‡´æ€§ï¼Œæ”¯æŒå¢é‡éªŒè¯å’Œè‡ªå®šä¹‰è§„åˆ™
5. **å·®åˆ†å¼•æ“**ï¼šé«˜æ•ˆçš„æ•°æ®å˜æ›´è¿½è¸ªå’Œç‰ˆæœ¬ç®¡ç†ï¼Œæ”¯æŒå†²çªè§£å†³
6. **å¤šæ¨¡å‹é€‚é…å™¨**ï¼šç»Ÿä¸€çš„AIæ¨¡å‹æ¥å£ï¼Œæ”¯æŒæ™ºèƒ½è·¯ç”±å’Œæ€§èƒ½ç›‘æ§

### ğŸš€ åº”ç”¨åœºæ™¯

- **ä¼ä¸šçº§åº”ç”¨**ï¼šé…ç½®ç®¡ç†ã€æ•°æ®åŒæ­¥ã€ç‰ˆæœ¬æ§åˆ¶
- **AIåº”ç”¨å¼€å‘**ï¼šæ¨¡å‹é›†æˆã€å“åº”å¤„ç†ã€æ€§èƒ½ä¼˜åŒ–
- **æ•°æ®å¤„ç†**ï¼šå®æ—¶åˆ†æã€æ‰¹é‡éªŒè¯ã€æ ¼å¼è½¬æ¢
- **Webåº”ç”¨**ï¼šè¡¨å•éªŒè¯ã€APIå“åº”å¤„ç†ã€ç”¨æˆ·äº¤äº’

### ğŸ’¡ æœ€ä½³å®è·µè¦ç‚¹

1. **æ€§èƒ½ä¼˜åŒ–**ï¼šä½¿ç”¨ç¼“å­˜ã€æ‰¹é‡å¤„ç†ã€å¼‚æ­¥æ“ä½œ
2. **é”™è¯¯å¤„ç†**ï¼šå®Œå–„çš„å¼‚å¸¸æ•è·å’Œæ¢å¤æœºåˆ¶
3. **ç›‘æ§å‘Šè­¦**ï¼šå®æ—¶ç›‘æ§ç³»ç»ŸçŠ¶æ€å’Œæ€§èƒ½æŒ‡æ ‡
4. **æ‰©å±•æ€§**ï¼šæ¨¡å—åŒ–è®¾è®¡ï¼Œæ”¯æŒè‡ªå®šä¹‰æ‰©å±•
5. **å®‰å…¨æ€§**ï¼šæ•°æ®éªŒè¯ã€è®¿é—®æ§åˆ¶ã€é…é¢ç®¡ç†

### ğŸ“ˆ è¿›é˜¶å»ºè®®

- æ ¹æ®å®é™…ä¸šåŠ¡éœ€æ±‚é€‰æ‹©åˆé€‚çš„åŠŸèƒ½ç»„åˆ
- å®šæœŸç›‘æ§å’Œä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½
- å»ºç«‹å®Œå–„çš„æµ‹è¯•å’Œéƒ¨ç½²æµç¨‹
- æŒç»­å…³æ³¨é¡¹ç›®æ›´æ–°å’Œç¤¾åŒºæœ€ä½³å®è·µ

é€šè¿‡æœ¬æŒ‡å—çš„å­¦ä¹ å’Œå®è·µï¼Œæ‚¨å°†èƒ½å¤Ÿå……åˆ†å‘æŒ¥AgentlyFormaté¡¹ç›®çš„å¼ºå¤§åŠŸèƒ½ï¼Œæ„å»ºé«˜æ•ˆã€ç¨³å®šçš„æ•°æ®å¤„ç†å’ŒAIåº”ç”¨ç³»ç»Ÿã€‚